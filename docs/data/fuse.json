{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title","getFn":null},{"path":["body"],"id":"body","weight":1,"src":"body","getFn":null}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Semantic Flow Documentation","n":0.577},"1":{"v":"\n**Dereferenceable, versioned semantic meshes** will be the foundation for a new era of knowledge graphs.\n\n[[now]] | [[todo]] | [[principle]] | [[dev.contributor.djradon.dev-log]]\n\n## What Is Semantic Flow?\n\n**Semantic Flow** is a framework for managing and publishing resource indicators, knowledge graphs and other semantic data by leveraging GitHub, Gitlab, and other free static hosting services. It enables a **dereferenceable Semantic Web** where every HTTP IRI returns meaningful content.\n\n[[concept.mesh-repo]] provide storage, [[concept.mesh]] provide resource management and publishing, and [[concept.semantic-site]] support data discovery and explainability.\n\n## Benefits\n\n- own your own self-describing data and data schemas\n- complete version history when you want it\n- reliable persistence\n- truly FAIR (Findable, Accessible, Interoperable, and Reusable)\n\n## Features\n\n- seamlessly integrate other data sources anywhere in your mesh\n- generate and customize mini-sites or single-page applications for nodes in your mesh\n- see [[feature]] for a list of planned features\n","n":0.086}}},{"i":2,"$":{"0":{"v":"Use Case","n":0.707}}},{"i":3,"$":{"0":{"v":"Use Case: Radio Show Websiste","n":0.447},"1":{"v":"\nSuppose DJ Radon wants to publish a website about himself, his musical activities, and maybe some album reviews. Call it a wiki, call it a knowledgebase, call it a show site. \n\nTo get started, he wants to publish his top-5 most-played tracks of the week. \n\nPublishing them as plain-text might be adequate for this situation, but say he eventually wanted to make his site linked: you can click from a playlist, to an album, to a track, to an artist. \n\nBut to get started:\n\n* A **namespace** `/test-ns/`\n* A **thing** `/ns/djradon/`\n* A **dataset** `/ns/djradon/picks/`\n\n#### Mesh Directory Structure\n\n```file\ntest-ns                    # namespace node\n   djradon                 # ref node (refering to a human dj)\n      bio                  # data node\n      picks                # data node \n      underbrush           # ref node\n         playlists         # data (series) node\n            1996-11-10     # data node\n            1996-11-17     # data node\n```\n\n#### Sample RDF (Turtle)\n\n1. **Namespace metadata**\n\n   ```turtle\n   # /ns/_id/ns_id.trig\n   <> a sf:Namespace ;\n      dct:title \"Namespace Root\" ;\n      sf:contains <https://example.org/ns/djradon/> .\n   ```\n\n2. **Thing metadata**\n\n   ```turtle\n   # /ns/djradon/_id/djradon_id.trig\n   <> a sf:Thing ;\n      rdfs:label \"djradon\" ;\n      sf:backlink <https://example.org/ns/> .\n   ```\n\n3. **Dataset metadata**\n\n   ```turtle\n   # /ns/djradon/picks/_id/picks_id.trig\n   <> a sf:VersionedDataset ;\n      dct:title \"djradon picks\" ;\n      sf:backlink <https://example.org/ns/djradon/> .\n   ```\n\n4. **Current distribution**\n\n   ```turtle\n   # /ns/djradon/picks/picks.trig\n   <> dct:issued \"2025-06-22\"^^xsd:date ;\n      dct:creator <https://example.org/agents/bot> .\n   ```\n\n5. **Historical version**\n\n   ```turtle\n   # /ns/djradon/picks/_v-series/v1/picks_v1.trig\n   <> dct:issued \"2025-06-01\"^^xsd:date .\n   ```\n\n---\n\nWith these few rules and a tiny folder-walking parser your **Semantic Mesh** is unambiguously self-describing, easy to validate, and ready for any RDF-aware tooling.\n","n":0.066}}},{"i":4,"$":{"0":{"v":"Todo","n":1}}},{"i":5,"$":{"0":{"v":"Product Ideas","n":0.707}}},{"i":6,"$":{"0":{"v":"Sparql Sync","n":0.707},"1":{"v":"\n- detects changes in a [[concept.semantic-site]] and updates a triple-store as appropriate\n- on demand, scans a triple-store and updates a site as appropriate.","n":0.209}}},{"i":7,"$":{"0":{"v":"Hateoas Driven API Recipe","n":0.5},"1":{"v":"\n## Your Use Case\n\nYou're not just documenting the API — you're using it:\n\n-   To **operate a mesh manually**, before clients exist.\n    \n-   You need an **executable interface**, not just static documentation.\n    \n-   You want **structured examples** (i.e. **recipes**) that can act as proto-clients or decision-paths.\n    \n-   You lean toward **HATEOAS** style: i.e., user follows links (or rels), maybe inputting small bits along the way.\n    \n\n___\n\n## 🔥 This is _not_ what Scalar is designed for\n\nScalar is a **docs tool**, great for:\n\n-   Rendering OpenAPI reference UIs.\n    \n-   Hosting and styling spec-based endpoints.\n    \n-   **Not** for chaining calls, dynamic flows, or acting like a human-in-the-loop client.\n    \n\nEven Stoplight or RapiDoc start to feel clunky in your context, because what you’re actually describing is closer to:\n\n### \\> ✅ A human-usable API client with structured, composable, inspectable **API macros or flows**\n\n___\n\n## 🚨 So yes, you probably need to build something.\n\nBut here's how to think about it critically, so you **don’t throw away everything** or reinvent everything either.\n\n___\n\n## 🧠 What You Actually Want: A “HATEOAS Recipe Runner”\n\nYou’re describing a system that does the following:\n\n| Feature                        | Description                                                    |\n| ------------------------------ | -------------------------------------------------------------- |\n| 🔧 **Embeds real OpenAPI**      | So you get type safety, endpoint listings, schemas, validation |\n| 🧪 **Can execute requests**     | Full HTTP interaction, possibly with state/cookies/token       |\n| 🪜 **Supports recipes/flows**   | Sequence of calls, possibly branching via hypermedia           |\n| 🧵 **Has local state/input**    | To reuse values from previous steps                            |\n| 📎 **HATEOAS link traversal**   | e.g. follow `\"next\"` or `\"create\"` link relations dynamically  |\n| 🧰 **Deno/TS-native**           | So it integrates with your mesh, Weave, etc.                   |\n| 🧭 **Interactive + replayable** | You can try things, backtrack, debug                           |\n\n## Your Use Case\n\nYou're not just documenting the API — you're using it:\n\n-   To **operate a mesh manually**, before clients exist.\n    \n-   You need an **executable interface**, not just static documentation.\n    \n-   You want **structured examples** (i.e. **recipes**) that can act as proto-clients or decision-paths.\n    \n-   You lean toward **HATEOAS** style: i.e., user follows links (or rels), maybe inputting small bits along the way.\n    \n\n___\n\n## 🔥 This is _not_ what Scalar is designed for\n\nScalar is a **docs tool**, great for:\n\n-   Rendering OpenAPI reference UIs.\n    \n-   Hosting and styling spec-based endpoints.\n    \n-   **Not** for chaining calls, dynamic flows, or acting like a human-in-the-loop client.\n    \n\nEven Stoplight or RapiDoc start to feel clunky in your context, because what you’re actually describing is closer to:\n\n### \\> ✅ A human-usable API client with structured, composable, inspectable **API macros or flows**\n\n___\n\n## 🚨 So yes, you probably need to build something.\n\nBut here's how to think about it critically, so you **don’t throw away everything** or reinvent everything either.\n\n___\n\n## 🧠 What You Actually Want: A “HATEOAS Recipe Runner”\n\nYou’re describing a system that does the following:\n\n| Feature                        | Description                                                    |\n| ------------------------------ | -------------------------------------------------------------- |\n| 🔧 **Embeds real OpenAPI**      | So you get type safety, endpoint listings, schemas, validation |\n| 🧪 **Can execute requests**     | Full HTTP interaction, possibly with state/cookies/token       |\n| 🪜 **Supports recipes/flows**   | Sequence of calls, possibly branching via hypermedia           |\n| 🧵 **Has local state/input**    | To reuse values from previous steps                            |\n| 📎 **HATEOAS link traversal**   | e.g. follow `\"next\"` or `\"create\"` link relations dynamically  |\n| 🧰 **Deno/TS-native**           | So it integrates with your mesh, Weave, etc.                   |\n| 🧭 **Interactive + replayable** | You can try things, backtrack, debug                           |\n\n## Your Use Case\n\nYou're not just documenting the API — you're using it:\n\n-   To **operate a mesh manually**, before clients exist.\n    \n-   You need an **executable interface**, not just static documentation.\n    \n-   You want **structured examples** (i.e. **recipes**) that can act as proto-clients or decision-paths.\n    \n-   You lean toward **HATEOAS** style: i.e., user follows links (or rels), maybe inputting small bits along the way.\n    \n\n___\n\n## 🔥 This is _not_ what Scalar is designed for\n\nScalar is a **docs tool**, great for:\n\n-   Rendering OpenAPI reference UIs.\n    \n-   Hosting and styling spec-based endpoints.\n    \n-   **Not** for chaining calls, dynamic flows, or acting like a human-in-the-loop client.\n    \n\nEven Stoplight or RapiDoc start to feel clunky in your context, because what you’re actually describing is closer to:\n\n### \\> ✅ A human-usable API client with structured, composable, inspectable **API macros or flows**\n\n___\n\n## 🚨 So yes, you probably need to build something.\n\nBut here's how to think about it critically, so you **don’t throw away everything** or reinvent everything either.\n\n___\n\n## 🧠 What You Actually Want: A “HATEOAS Recipe Runner”\n\nYou’re describing a system that does the following:\n\n| Feature                        | Description                                                    |\n| ------------------------------ | -------------------------------------------------------------- |\n| 🔧 **Embeds real OpenAPI**      | So you get type safety, endpoint listings, schemas, validation |\n| 🧪 **Can execute requests**     | Full HTTP interaction, possibly with state/cookies/token       |\n| 🪜 **Supports recipes/flows**   | Sequence of calls, possibly branching via hypermedia           |\n| 🧵 **Has local state/input**    | To reuse values from previous steps                            |\n| 📎 **HATEOAS link traversal**   | e.g. follow `\"next\"` or `\"create\"` link relations dynamically  |\n| 🧰 **Deno/TS-native**           | So it integrates with your mesh, Weave, etc.                   |\n| 🧭 **Interactive + replayable** | You can try things, backtrack, debug                           |\n\n## Your Use Case\n\nYou're not just documenting the API — you're using it:\n\n-   To **operate a mesh manually**, before clients exist.\n    \n-   You need an **executable interface**, not just static documentation.\n    \n-   You want **structured examples** (i.e. **recipes**) that can act as proto-clients or decision-paths.\n    \n-   You lean toward **HATEOAS** style: i.e., user follows links (or rels), maybe inputting small bits along the way.\n    \n\n___\n\n## 🔥 This is _not_ what Scalar is designed for\n\nScalar is a **docs tool**, great for:\n\n-   Rendering OpenAPI reference UIs.\n    \n-   Hosting and styling spec-based endpoints.\n    \n-   **Not** for chaining calls, dynamic flows, or acting like a human-in-the-loop client.\n    \n\nEven Stoplight or RapiDoc start to feel clunky in your context, because what you’re actually describing is closer to:\n\n### \\> ✅ A human-usable API client with structured, composable, inspectable **API macros or flows**\n\n___\n\n## 🚨 So yes, you probably need to build something.\n\nBut here's how to think about it critically, so you **don’t throw away everything** or reinvent everything either.\n\n___\n\n## 🧠 What You Actually Want: A “HATEOAS Recipe Runner”\n\nYou’re describing a system that does the following:\n\n| Feature                        | Description                                                    |\n| ------------------------------ | -------------------------------------------------------------- |\n| 🔧 **Embeds real OpenAPI**      | So you get type safety, endpoint listings, schemas, validation |\n| 🧪 **Can execute requests**     | Full HTTP interaction, possibly with state/cookies/token       |\n| 🪜 **Supports recipes/flows**   | Sequence of calls, possibly branching via hypermedia           |\n| 🧵 **Has local state/input**    | To reuse values from previous steps                            |\n| 📎 **HATEOAS link traversal**   | e.g. follow `\"next\"` or `\"create\"` link relations dynamically  |\n| 🧰 **Deno/TS-native**           | So it integrates with your mesh, Weave, etc.                   |\n| 🧭 **Interactive + replayable** | You can try things, backtrack, debug                           |\n\n## Your Use Case\n\nYou're not just documenting the API — you're using it:\n\n-   To **operate a mesh manually**, before clients exist.\n    \n-   You need an **executable interface**, not just static documentation.\n    \n-   You want **structured examples** (i.e. **recipes**) that can act as proto-clients or decision-paths.\n    \n-   You lean toward **HATEOAS** style: i.e., user follows links (or rels), maybe inputting small bits along the way.\n    \n\n___\n\n## 🔥 This is _not_ what Scalar is designed for\n\nScalar is a **docs tool**, great for:\n\n-   Rendering OpenAPI reference UIs.\n    \n-   Hosting and styling spec-based endpoints.\n    \n-   **Not** for chaining calls, dynamic flows, or acting like a human-in-the-loop client.\n    \n\nEven Stoplight or RapiDoc start to feel clunky in your context, because what you’re actually describing is closer to:\n\n### \\> ✅ A human-usable API client with structured, composable, inspectable **API macros or flows**\n\n___\n\n## 🚨 So yes, you probably need to build something.\n\nBut here's how to think about it critically, so you **don’t throw away everything** or reinvent everything either.\n\n___\n\n## 🧠 What You Actually Want: A “HATEOAS Recipe Runner”\n\nYou’re describing a system that does the following:\n\n| Feature                        | Description                                                    |\n| ------------------------------ | -------------------------------------------------------------- |\n| 🔧 **Embeds real OpenAPI**      | So you get type safety, endpoint listings, schemas, validation |\n| 🧪 **Can execute requests**     | Full HTTP interaction, possibly with state/cookies/token       |\n| 🪜 **Supports recipes/flows**   | Sequence of calls, possibly branching via hypermedia           |\n| 🧵 **Has local state/input**    | To reuse values from previous steps                            |\n| 📎 **HATEOAS link traversal**   | e.g. follow `\"next\"` or `\"create\"` link relations dynamically  |\n| 🧰 **Deno/TS-native**           | So it integrates with your mesh, Weave, etc.                   |\n| 🧭 **Interactive + replayable** | You can try things, backtrack, debug                           |\n\n## Your Use Case\n\nYou're not just documenting the API — you're using it:\n\n-   To **operate a mesh manually**, before clients exist.\n    \n-   You need an **executable interface**, not just static documentation.\n    \n-   You want **structured examples** (i.e. **recipes**) that can act as proto-clients or decision-paths.\n    \n-   You lean toward **HATEOAS** style: i.e., user follows links (or rels), maybe inputting small bits along the way.\n    \n\n___\n\n## 🔥 This is _not_ what Scalar is designed for\n\nScalar is a **docs tool**, great for:\n\n-   Rendering OpenAPI reference UIs.\n    \n-   Hosting and styling spec-based endpoints.\n    \n-   **Not** for chaining calls, dynamic flows, or acting like a human-in-the-loop client.\n    \n\nEven Stoplight or RapiDoc start to feel clunky in your context, because what you’re actually describing is closer to:\n\n### \\> ✅ A human-usable API client with structured, composable, inspectable **API macros or flows**\n\n___\n\n## 🚨 So yes, you probably need to build something.\n\nBut here's how to think about it critically, so you **don’t throw away everything** or reinvent everything either.\n\n___\n\n## 🧠 What You Actually Want: A “HATEOAS Recipe Runner”\n\nYou’re describing a system that does the following:\n\n| Feature                        | Description                                                    |\n| ------------------------------ | -------------------------------------------------------------- |\n| 🔧 **Embeds real OpenAPI**      | So you get type safety, endpoint listings, schemas, validation |\n| 🧪 **Can execute requests**     | Full HTTP interaction, possibly with state/cookies/token       |\n| 🪜 **Supports recipes/flows**   | Sequence of calls, possibly branching via hypermedia           |\n| 🧵 **Has local state/input**    | To reuse values from previous steps                            |\n| 📎 **HATEOAS link traversal**   | e.g. follow `\"next\"` or `\"create\"` link relations dynamically  |\n| 🧰 **Deno/TS-native**           | So it integrates with your mesh, Weave, etc.                   |\n| 🧭 **Interactive + replayable** | You can try things, backtrack, debug                           |\n\n## Your Use Case\n\nYou're not just documenting the API — you're using it:\n\n-   To **operate a mesh manually**, before clients exist.\n    \n-   You need an **executable interface**, not just static documentation.\n    \n-   You want **structured examples** (i.e. **recipes**) that can act as proto-clients or decision-paths.\n    \n-   You lean toward **HATEOAS** style: i.e., user follows links (or rels), maybe inputting small bits along the way.\n    \n\n___\n\n## 🔥 This is _not_ what Scalar is designed for\n\nScalar is a **docs tool**, great for:\n\n-   Rendering OpenAPI reference UIs.\n    \n-   Hosting and styling spec-based endpoints.\n    \n-   **Not** for chaining calls, dynamic flows, or acting like a human-in-the-loop client.\n    \n\nEven Stoplight or RapiDoc start to feel clunky in your context, because what you’re actually describing is closer to:\n\n### \\> ✅ A human-usable API client with structured, composable, inspectable **API macros or flows**\n\n___\n\n## 🚨 So yes, you probably need to build something.\n\nBut here's how to think about it critically, so you **don’t throw away everything** or reinvent everything either.\n\n___\n\n## 🧠 What You Actually Want: A “HATEOAS Recipe Runner”\n\nYou’re describing a system that does the following:\n\n| Feature                        | Description                                                    |\n| ------------------------------ | -------------------------------------------------------------- |\n| 🔧 **Embeds real OpenAPI**      | So you get type safety, endpoint listings, schemas, validation |\n| 🧪 **Can execute requests**     | Full HTTP interaction, possibly with state/cookies/token       |\n| 🪜 **Supports recipes/flows**   | Sequence of calls, possibly branching via hypermedia           |\n| 🧵 **Has local state/input**    | To reuse values from previous steps                            |\n| 📎 **HATEOAS link traversal**   | e.g. follow `\"next\"` or `\"create\"` link relations dynamically  |\n| 🧰 **Deno/TS-native**           | So it integrates with your mesh, Weave, etc.                   |\n| 🧭 **Interactive + replayable** | You can try things, backtrack, debug                           |\n\n## Your Use Case\n\nYou're not just documenting the API — you're using it:\n\n-   To **operate a mesh manually**, before clients exist.\n    \n-   You need an **executable interface**, not just static documentation.\n    \n-   You want **structured examples** (i.e. **recipes**) that can act as proto-clients or decision-paths.\n    \n-   You lean toward **HATEOAS** style: i.e., user follows links (or rels), maybe inputting small bits along the way.\n    \n\n___\n\n## 🔥 This is _not_ what Scalar is designed for\n\nScalar is a **docs tool**, great for:\n\n-   Rendering OpenAPI reference UIs.\n    \n-   Hosting and styling spec-based endpoints.\n    \n-   **Not** for chaining calls, dynamic flows, or acting like a human-in-the-loop client.\n    \n\nEven Stoplight or RapiDoc start to feel clunky in your context, because what you’re actually describing is closer to:\n\n### \\> ✅ A human-usable API client with structured, composable, inspectable **API macros or flows**\n\n___\n\n## 🚨 So yes, you probably need to build something.\n\nBut here's how to think about it critically, so you **don’t throw away everything** or reinvent everything either.\n\n___\n\n## 🧠 What You Actually Want: A “HATEOAS Recipe Runner”\n\nYou’re describing a system that does the following:\n\n| Feature                        | Description                                                    |\n| ------------------------------ | -------------------------------------------------------------- |\n| 🔧 **Embeds real OpenAPI**      | So you get type safety, endpoint listings, schemas, validation |\n| 🧪 **Can execute requests**     | Full HTTP interaction, possibly with state/cookies/token       |\n| 🪜 **Supports recipes/flows**   | Sequence of calls, possibly branching via hypermedia           |\n| 🧵 **Has local state/input**    | To reuse values from previous steps                            |\n| 📎 **HATEOAS link traversal**   | e.g. follow `\"next\"` or `\"create\"` link relations dynamically  |\n| 🧰 **Deno/TS-native**           | So it integrates with your mesh, Weave, etc.                   |\n| 🧭 **Interactive + replayable** | You can try things, backtrack, debug                           |\n\n## Your Use Case\n\nYou're not just documenting the API — you're using it:\n\n-   To **operate a mesh manually**, before clients exist.\n    \n-   You need an **executable interface**, not just static documentation.\n    \n-   You want **structured examples** (i.e. **recipes**) that can act as proto-clients or decision-paths.\n    \n-   You lean toward **HATEOAS** style: i.e., user follows links (or rels), maybe inputting small bits along the way.\n    \n\n___\n\n## 🔥 This is _not_ what Scalar is designed for\n\nScalar is a **docs tool**, great for:\n\n-   Rendering OpenAPI reference UIs.\n    \n-   Hosting and styling spec-based endpoints.\n    \n-   **Not** for chaining calls, dynamic flows, or acting like a human-in-the-loop client.\n    \n\nEven Stoplight or RapiDoc start to feel clunky in your context, because what you’re actually describing is closer to:\n\n### \\> ✅ A human-usable API client with structured, composable, inspectable **API macros or flows**\n\n___\n\n## 🚨 So yes, you probably need to build something.\n\nBut here's how to think about it critically, so you **don’t throw away everything** or reinvent everything either.\n\n___\n\n## 🧠 What You Actually Want: A “HATEOAS Recipe Runner”\n\nYou’re describing a system that does the following:\n\n| Feature                        | Description                                                    |\n| ------------------------------ | -------------------------------------------------------------- |\n| 🔧 **Embeds real OpenAPI**      | So you get type safety, endpoint listings, schemas, validation |\n| 🧪 **Can execute requests**     | Full HTTP interaction, possibly with state/cookies/token       |\n| 🪜 **Supports recipes/flows**   | Sequence of calls, possibly branching via hypermedia           |\n| 🧵 **Has local state/input**    | To reuse values from previous steps                            |\n| 📎 **HATEOAS link traversal**   | e.g. follow `\"next\"` or `\"create\"` link relations dynamically  |\n| 🧰 **Deno/TS-native**           | So it integrates with your mesh, Weave, etc.                   |\n| 🧭 **Interactive + replayable** | You can try things, backtrack, debug                           |","n":0.02}}},{"i":8,"$":{"0":{"v":"Fluree Connector","n":0.707},"1":{"v":"\n## User Story\n\nAs a user of semantic meshes, I would like to be able to query an RDF database\nthat is synced to my [[concept.mesh-repo]]. Fluree is one option -- it has\na cloud version for easy data hosting\n","n":0.164}}},{"i":9,"$":{"0":{"v":"Principles","n":1}}},{"i":10,"$":{"0":{"v":"Single Referent Principle","n":0.577},"1":{"v":"\n- An IRI should refer to only one thing\n- this is NOT the \"single name\" principle; multiple IRIs can refer to the same thing","n":0.204}}},{"i":11,"$":{"0":{"v":"pseudo-immutability","n":1},"1":{"v":"\nIn a filesystem-based structure like a [[sflo.concept.mesh]], you can't really prevent changes. But some things in a mesh should be treated as immutable, like [[sflo.concept.mesh.resource.element.flow.snapshot.version]] and [[sflo.concept.relative-identifier]].\n\n**Pseudo-immutability** acknowledges that things might be changed, for various reasons:\n\n- accidental changes\n- \"cleaning up\" of data for legal reasons, e.g.: personally-identifiable information (PII) or \"the right to be forgotten.\"\n- fixing of typos or other errors\n- re-organizing namespaces\n\nIf you're updating a dataset, the principle of pseudo-immutability is preserved in that the old data can still exist and be discoverable from the metadata \n\n\n**Psuedo-immutability** also acknowledges that for non-atomic data especially, \"the next version\" is going to keep changing until a checkout or \"weave\". And that sometime you want the \"latest\" data for a given resource, and without sophisticated database management (e.g., )\n\n\n## Mitigations\n\n- metadata can track changes and supply reasons\n- tooling can be used to make changes in ways that don't break the API","n":0.082}}},{"i":12,"$":{"0":{"v":"Dereferencability for Humans","n":0.577},"1":{"v":"\nIf you put any [[sflo.concept.mesh.resource]]'s URL in a browser, it should return some useful context. \n\n \n\n\n## References\n\n- https://ld4pe.dublincore.org/learning_resource/making-uris-published-on-data-web-rdf-dereferencable/","n":0.229}}},{"i":13,"$":{"0":{"v":" Now","n":1}}},{"i":14,"$":{"0":{"v":"Features","n":1}}},{"i":15,"$":{"0":{"v":"Handling Renaming","n":0.707},"1":{"v":"\n- if a namespace-iri is changed, gulp, the old one can be preserved with a \"redirect\" predicate in the [[concept.mesh.resource.element.flow.metadata]] and a warning on the html page\n","n":0.192}}},{"i":16,"$":{"0":{"v":"Check Namespace before Creating","n":0.5},"1":{"v":"\n- when creating a new repo, sflow should check whether there's an existing folder with the same name in the parent user/org site.\n- best practice is probably not to put an sflow-site at the user/org level? At least if it might have repos someday.\n\n## References\n\n- [[sflo.issue.github-bare-namespace-can-overlap-with-repo-namespaces]]","n":0.147}}},{"i":17,"$":{"0":{"v":"Changing Historical Datasets","n":0.577},"1":{"v":"\n- it's better if you don't have to, but if you do... \n  - maybe hashes should be stored for distributions, so people can detect that they've changed.","n":0.189}}},{"i":18,"$":{"0":{"v":"FAQ","n":1},"1":{"v":"\n# Semantic Flow Frequently Asked Questions\n\nThis section addresses common questions about Semantic Flow design principles and architecture.\n\n## Design Principles\n\n### [[Why don't namespace nodes have reference flows?|faq.why-dont-namespace-and-data-nodes-have-reference-flows]]\nWhy should a namespace have to refer to something?\n\n### [[Why are there elements at the top of a repo?|faq.why-are-there-elements-at-the-top-of-a-repo]]\nThe repository root can be a mesh node, in which case `_meta-component/` and `_handle/` elements appear at the top level. \n\n## Architecture Questions\n\n*More FAQ entries will be added as common questions arise.*\n\n---\n\n**Contributing to FAQ**: If you encounter questions that would benefit from clear explanations, consider adding them to this FAQ section following the established pattern.\n","n":0.101}}},{"i":19,"$":{"0":{"v":"Why Not Use Git Semantics for Versioning","n":0.378},"1":{"v":"\n// TODO","n":0.707}}},{"i":20,"$":{"0":{"v":"Why don't namespace nodes have reference flows?","n":0.378},"1":{"v":"\n## Question\n\nWhy don't [[namespace nodes|concept.mesh.resource.node.namespace]] and [[concept.mesh.resource.node.data]] have [[reference flows|concept.mesh.resource.element.flow.reference]] like [[reference nodes|concept.mesh.resource.node.reference]] do?\n\n## Answer\n\nURLs that correspond to namespace nodes and data nodes don't have a referent other than themselves. This helps avoid ambiguity when interpreting their URLs. (see the [[principle.single-referent]]). \n\ne.g.:\n- `ns/` : doesn't refer to anything, it's just a namespace\n- `ns/people` : does this refer to people in general, i.e. conceptually? or to a dataset? if it's got a data flow, it refers to a dataset. If it's got a reference flow, it refers to something other than a dataset.\n\nSince reference nodes can do everything namespace nodes can do (i.e., contain other nodes), there's no drawback to making namespace nodes into reference nodes.\n","n":0.093}}},{"i":21,"$":{"0":{"v":"Why Dont Data Nodes Contain Distributions Directly","n":0.378},"1":{"v":"\n## Question\n\nWhy don't [[data nodes|concept.mesh.resource.node.data]] contain distribution files directly? Why do I need to go to `_current/` to find the actual data?\n\n## Answer\n\nData nodes represent **abstract data concepts**, not concrete data instances. This separation provides several important benefits:\n\n### Clear Semantic Distinction\n\n- **Data node** (`/ns/monsters/`): \"The concept of monster data\"\n- **Data compound** (`/ns/monsters/_data-component/`): \"The abstract dataset associated with the monster data concept\" \n- **Data compound layers**: the current, next and historical versions of the dataset\n\nThis allows you to reference the concept separately from the associated abstract or concrete dataset.\n\n### Stable Identity\n\nThe data node and data compound provide permanent, stable identifier for the concept and its data payload that persist even as the concrete data changes over time. You can always refer to \"monster data as a concept\" using `/ns/monsters/` regardless of how many versions exist.\n\n### Temporal Organization\n\nBy separating the concept from concrete instances, data nodes can cleanly organize different temporal states:\n- `_current/` - current data\n- `_next/` - draft changes  \n- `_v1/`, `_v2/` - historical versions\n\n### Consistent Architecture\n\nThis mirrors how [[reference nodes|concept.mesh.resource.node.reference]] work:\n- **Reference nodes**: Abstract entity concept + `_ref/` element with concrete data\n- **Data nodes**: Abstract data concept + `_current/` element with concrete data\n\n### Metadata Separation\n\nThe data node's [[metadata flow|concept.mesh.resource.element.flow.metadata]] contains system metadata about the data concept and its components, while each [[concept.mesh.resource.element.flow.data]] can also contain (concept-specific) metadata.\n\nTODO: example\n\n\n## Analogy\n\nThink of it like a library:\n- **Data node** = \"The concept of the Encyclopedia Britannica\"\n- **data flow** = The Encyclopedia Britannica as an ongoing series of editions\n- **[[concept.mesh.resource.element.flow.snapshot]]** = Specific editions (1990 edition, 2020 edition, current edition)\n\nYou can refer to \"Encyclopedia Britannica\" as a general concept or as a series without specifying which edition, or you can reference a specific edition when you need concrete data.\n","n":0.059}}},{"i":22,"$":{"0":{"v":"Why are there elements at the top of a repo?","n":0.316},"1":{"v":"\n## Question\n\nWhy are there [[mesh elements|concept.mesh.resource.element]] like `_meta/`, `_handle/`, and `_assets/` at the top level of a repository? Shouldn't elements only be inside nodes?\n\n## Answer\n\nElements at the repository root exist because **the repository root itself is a [[mesh node|concept.mesh.resource.node]]** - specifically, it's the [[root node|concept.root-node]] of the mesh.\n\n### Repository Root = Mesh Root Node\n\nEvery semantic mesh has a root node, and in a repository-based mesh, the repository root **is** that root node. It's a \"nameless\" node locally (represented as \"/\") that can be any type of mesh node:\n\n- **Namespace node**: If the repo organizes other nodes\n- **data node**: If the repo represents a single dataset  \n- **Reference node**: If the repo represents an external entity\n\nSince the repository root is a mesh node, it follows the same rules as any other node and must contain:\n\n- **`_meta/`**: corresponds to the [[concept.mesh.resource.element.flow.metadata]] with administrative metadata for the root node\n- **`_handle/`**: corresponds to [[node handle|concept.mesh.resource.element.handle]] for referential indirection\n\nThe root node may contain **other elements**: Depending on the root node type (e.g., `_ref/` for reference nodes, `_data/` for versioned datasets)\n\n### Consistency Principle\n\nThis maintains architectural consistency: **every mesh node has the same structure and capabilities**, whether it's nested deep in the hierarchy or at the repository root. The root node isn't special - it's just the top-level node in the mesh hierarchy.\n\n### Mesh Self-Containment\n\nThis design also supports the principle that **any subtree is a complete mesh**. The repository root, being a proper mesh node with all its elements, ensures the entire repository is a self-contained, functional semantic mesh.","n":0.063}}},{"i":23,"$":{"0":{"v":"Development","n":1},"1":{"v":"\n## Building the docs\n\n```shell\nnpx dendron publish export --target github --yes\n```\n\n## Monorepo layout\n\n```\nsflo/\n  cli/                        # the sflo CLI (binary)\n  plugins/\n    elements/\n    mesh-server/              # static mesh server(s)\n    sflo-web/                 # your web UI, if you want it as a plugin\n    sflo-api/\n    sparql/\n    sparql-update/\n    sparql-editor/            # SIB Swiss editor at /play\n  sflo-host/                  # the big service that loads plugins\n  shared/\n    core/                     # RDFine/LDKit, SHACL, types\n    auth/                     # JWT + GitHub device flow\n    config/                   # runtime/config loaders (RDF/JSON)\n    utils/                    # misc helpers\n```\n\n\n## Hot Reload\n\nThe development setup includes automatic hot reload using nodemon:\n\n- **Watches**: `sflo-host/src`, `plugins/*/src`, `shared/*/src`\n- **Auto-restarts** when any watched file changes\n- **Loads plugins from source** in development mode (not built `dist` files)\n- **Preserves debugger connection** after restart\n","n":0.094}}},{"i":24,"$":{"0":{"v":"Testing","n":1},"1":{"v":"\n## Available Scripts\n\n- `pnpm test` - Run all tests once\n- `pnpm test:watch` - Run tests in watch mode (automatically re-runs tests when files change)\n- `pnpm test:ui` - Run tests with Vitest UI (visual interface in browser)\n- `pnpm test:coverage` - Run tests with coverage report\n\n## Watch Mode\n\nWatch mode automatically re-runs your tests whenever you save changes to:\n- Test files (`.test.ts`, `.spec.ts`)\n- Source files being tested\n- Dependencies of those files\n\nThis provides instant feedback during development - you can see test results immediately after making changes without manually re-running tests.\n\n## Debugging Tests\n\n1. **Open a test file** in VSCode\n2. **Set breakpoints** in the test or source code\n3. **Select \"Debug Current Test File\"** configuration\n4. **Press F5** to debug the current test file\n\n## Test Structure\n\nTests are located in `__tests__` directories within each package:\n- `sflo-host/src/__tests__/` - Tests for the host service\n- Add similar directories in other packages as needed\n","n":0.084}}},{"i":25,"$":{"0":{"v":"Semantic Flow General Guidance","n":0.5},"1":{"v":"\n**Semantic Flow** is a framework for managing knowledge graphs and other Semantic Web resources in publish-ready [[semantic meshes|concept.mesh]]\n\n## Workspace Components\n\n- The sflow-platform repo/folder is organized as a monorepo, divided into a few different modules:\n  - **sflo-host/**: host service with plugin architecture\n  - **sflo-api/**: plugin providing Semantic Flow functionality via REST\n  - **cli/**: Command-line application that consumes the sflo-api\n  - **sflo-web/**: Web frontend, can connect to any sflo-api instance\n  - **shared/**: cross-cutting code like type schemas (core), logging, and config\n- **test-ns/** repo: Test mesh repo\n- **ontology/**: repo containing relevant ontologies:\n  - `mesh` - Core mesh architecture with base classes (Resource, Node, Element) and fundamental types\n  - `node` - Node operations including Handle, Flow types, and operational relationships\n  - `flow` - Temporal concepts including Snapshot types and versioning relationships\n  - `config-flow` - Configuration properties that apply directly to mesh entities (nodes, flows, snapshots, etc.)\n  - `meta-flow` - provenance and licensing vocabulary\n  - `flow-service` - Service layer configuration vocabulary for the flow-service application\n\n## Key Concepts\n\n### Semantic Mesh\n\nA dereferenceable, versioned collection of semantic data and supporting resources, where every HTTP URI returns meaningful content. See [[concept.mesh]]\n\n#### Core Components\n\n- **Mesh Resources**:\n  - **Nodes**: Semantic Atoms\n    - **Dataset Nodes**: Bundles of data with optional quasi-immutable, versioned history\n    - **Namespace Nodes**: basically empty folders for URL-based hierarchical organization\n    - **Reference Nodes**: Refer to \"things that exist\" like people, or songs, or ideas\n  - **Elements**: things that help define and systematize the nodes\n    - **Flows**: datasets for node metadata, reference data, and payload data\n      - **Snapshots**: temporal slices of a flow, containing RDF dataset distributions\n    - **Handles**: things that let you refer to a node as a node instead of as its referent\n    - **Asset Trees**: elements that allow you to attach arbitrary collections of files and folders to a mesh; in a sense, these things are \"outside\" the mesh, and other than the top-level \"_meta\" folder, they don't contain any other mesh resources\n\n### Semantic Flow Workflow:\n\n- In General: Mesh resource addition & editing → Weaving\n- a mesh is servable \"as-is\", so if the git provider is configure to serve it as a website, no additional publishing step is required (beyond commit)\n\n### Semantic Site\n\n- The repo IS the site:\n  - can be served locally\n  - no separate SSG (Static Site Generator) necessary\n    - but static resource page generation should happen on every weave as necessary\n  - after push, you should be able to see the changed mesh at the corresponding github pages URL\n\n## RDF and Semantic Web\n\n- avoid use of blank nodes\n- prefer relative/local URIs for transposability/composability\n- meshes support multiple RDF formats (.trig, .jsonld, etc.)\n  - .trig might be better for user-facing content\n  - .jsonld might be better for system content\n- be mindful of RDF terminology and concepts\n  - extends DCAT for dataset catalogs\n  - extends PROV for provenance, with relator-based contexts\n- When referring to IRIs or URIs that are part of a semantic mesh, prefer the term URLs instead of IRI or URI\n  - if you see a reference to IRI or URI, it might need updating, or it might mean a distinction should be drawn\n- RDF comments should be extremely concise and clear.\n\n### Quadstore\n\n- make sure you are familiar with [[sflo.tech-stack.quadstore.readme]], which documents the API\n- For testability and in case we ever want to use multiple stores simultaneously, store-accessing functions take a QuadstoreBundle\n- quadstore API calls use \"undefined\" instead of \"null\" to represent the wildcard for subjects, predicates, objects, and graphs\n\n## Documentation\n\n- Avoid numbering of code comments, headings and list items, as it makes re-ordering a pain\n- All specifications and design docs are in `sflo-dendron-notes/`\n- Check conversation logs in `sflo.conv.*` for context on design decisions if necessary, but beware of superceded and dangerously-outdated info\n\n### Documentation First\n\n- unclear or anemic documentation should be called out\n- documentation should be wiki-style: focused on the topic at hand, don't repeat yourself, keep things simple and clear\n- when assisting with writing documentation, it should be kept concise and specific to the topic at hand\n- whenever documentation is updated, any corresponding LLM conversation context should be updated too\n- to encourage documentation-driven software engineering, code comments should refer to corresponding documentation by filename, and the documentation and code should be cross-checked for consistency whenever possible\n\n### Documentation Architecture\n\n- `sflo-dendron-notes` repo has wiki-style notes about the mesh architecture\n  -  Dendron handles the frontmatter... don't rewrite IDs or anything else in the frontmatter\n- official project documentation should be generated in `documentation` directory in markdown\n\n### Project notes\n\nProject documentation, specifications, and design choices are stored in `documentation/` using Dendron's hierarchical note system. Key documentation hierarchies include:\n\n- **Concepts**: `concept.*` files talk about general Semantic Flow concepts\n- **Mesh docs**: `concept.mesh.*` files define the semantic mesh architecture\n- **Product specifications**: `product.*` files detail each component\n- **Use cases**: `use-cases.*` for feature planning and testing\n\n### Component Development with Docs\n\n- Each module (flow-cli, flow-service, flow-web) should follow the architecture defined in the documentation\n- Refer to `sflo.product.*` files for component-specifc descriptions, requirements, etc\n\n## Project Architecture\n\n### Configuration Architecture\n\n- The project uses a sophisticated JSON-LD based configuration system with multiple layers\n- **Service Configuration resolution order**: CLI arguments → Environment variables → Config file → Defaults\n- The [`defaults.ts`](semantic-flow/flow-service/src/config/defaults.ts) file is the source for \"platform default\" configuration\n\n### Logging System Architecture\n\n- **Structured logging** with rich `LogContext` interface is the preferred approach\n- **Three-channel logging architecture**:\n  - Console logging (pretty format for development)\n  - File logging (pretty format for human readability)\n  - Sentry logging (structured JSON for error tracking)\n- **Graceful degradation principle**: Logging failures should never crash the application\n\n### Logging System Patterns\n\n- `let logger = getComponentLogger(import.meta);` at the start of every file\n\n### Error Handling Patterns\n\n- Use the [`handleCaughtError`](semantic-flow/flow-service/src/utils/logger.ts) utility for consistent error handling\n- **Documentation**: See [error-handling-usage.md](semantic-flow/flow-service/documentation/error-handling-usage.md) for comprehensive usage examples\n- The error handling system integrates with all logging tiers (console, file, Sentry)\n\n### File Organization\n\n- **Import paths** require careful attention when reorganizing files to avoid breaking dependencies\n\n### Implementation Patterns\n\n- **Proper TypeScript interfaces** for configuration validation and type safety\n- **SHACL constraints** for JSON-LD validation when working with semantic data\n- **Modular design**: Keep utilities focused and avoid circular dependencies between core modules\n\n## Coding Standards\n\n### Language & Runtime\n\n- **TypeScript**: Use strict TypeScript configuration with modern ES2022+ features\n- Use NodeJS v24 and the latest best practices\n\n### RDF Data Handling\n\n- **Primary Format**: .trig files for RDF data storage and processing\n- **Secondary Format**: Full JSON-LD support required\n- **RDF Libraries**: Use RDF.js ecosystem libraries consistently across components\n- **Namespace Management**: Follow URL-based identifier patterns as defined in `sflo.concept.identifier.md`\n- **Reserved Names**: Validate against underscore-prefixed reserved identifiers per `sflo.concept.identifier.md`\n- The most effective validation strategy combines TypeScript structural validation with RDF semantic validation:\n\n### Semantic Mesh Architecture\n\n- **Resource Types**: Nodes are the foundation, Elements support Nodes, Flows are \"abstract datasets\", and \"Snapshots\" are their temporal slices as defined in `sflo.concept.mesh.md`\n- **Folder Structure**: Validate mesh folder structures (dataset nodes, namespace nodes, etc.)\n- **System Elements**: Distinguish between system-generated and user-modifiable elements\n- **Weave Integration**: Code must support weave operations as defined in `sflo.concept.weave.md`\n\n### Documentation-Driven Development\n\n- **Code Comments**: reference corresponding documentation by filename (e.g., `// See sflo.concept.mesh.resource.node.md`)\n- **Interface Definitions**: Link to concept documentation in TSDoc comments\n- **Cross-Reference Validation**: Ensure consistency between code and documentation; if docs need updating, let me know\n- **API Documentation**: Generate from TSDoc comments?\n\n### Component Architecture\n\n- **Shared code**: should go in flow-core/\n- **Separation**: Maintain clear boundaries between flow-cli, flow-service, and flow-web\n- **Error Handling**: Use consistent error patterns across all components\n- **Async Patterns**: Use async/await for RDF operations and file I/O\n- **Type Safety**: Leverage TypeScript's type system for mesh resource validation\n\n### File Organization & Naming\n\n- **TypeScript Modules**: Use `.ts` extension, organize by feature/component\n- **Test Files**:\n  - unit test files go in tests/unit/ using `.test.ts` suffix\n  - integration tests go in tests/integration\n- **Mesh Resources**: Follow mesh resource naming conventions from @/ontology/alpha/_node-data/_next/flow-ontology-alpha.trig\n- **Constants**: Use UPPER_SNAKE_CASE for constants, especially for reserved names; centralize constants, e.g. semantic-flow/flow-core/src/mesh-constants.ts\n- **File size**: For ease of AI-based editing, prefer lots of small files over one huge file\n- **Quoting**: For easier compatibility with JSON files, use double quotes everywhere\n\n### Code Style\n\n- If using any is actually clearer than not using it, it's okay, just add the // deno-lint-ignore comment\n- Use `satisfies` whenever you're writing a literal config object that should be checked against a TypeScript shape, but you want to retain the full type of the literal for use in your program.\n\n### Error Handling\n\n- **Custom Errors**: Create semantic mesh-specific error types\n- **Validation**: Validate mesh resource structures before processing\n- **Logging**: Use structured logging for debugging weave operations\n- **Async Error Propagation**: Properly handle async/await error chains\n\n#### Enhanced Error Handling with LogContext\n\nThe platform uses **LogContext-enhanced error handling** from `flow-core/src/utils/logger/error-handlers.ts` for consistent error logging across all components. Both error handling functions now accept optional `LogContext` parameters for rich contextual information.\n\n**Core Functions:**\n- `handleCaughtError()` - For caught exceptions with comprehensive error type handling\n- `handleError()` - For controlled error scenarios with structured messaging\n\n#### LogContext Structure\n\n#### handleCaughtError Examples\n\n\n**Startup Error Handling:**\n\n\nThis pattern ensures **uniform error reporting** with rich contextual information, **easier debugging** through structured logging, and **consistent integration** with console, file, and Sentry logging tiers.\n\n\n### Testing\n\n- **Unit Tests**: place unit tests in `src/__tests__` folder; with `.test.ts` suffix; target ≥80% critical-path coverage and include both success and failure cases.\n- **Integration Tests**: Test mesh operations end-to-end; tests are located in test/integration/ dir\n- **RDF Validation**: Test both .trig and JSON-LD parsing/serialization\n- **Mock Data**: Create test mesh structures following documentation patterns\n- after you think you've completed a task, check for any \"problems\", i.e., deno-lint\n\n### Performance\n\n- **RDF Processing**: Stream large RDF files where possible\n- **File I/O**: Use async file operations consistently\n","n":0.025}}},{"i":26,"$":{"0":{"v":"Debugging","n":1},"1":{"v":"\n## Available Scripts\n\n### Root Level\n\n- `pnpm dev` - Start sflo-host with hot reload (nodemon + tsx)\n- `pnpm dev:debug` - Start sflo-host with hot reload and debugging enabled\n- `pnpm dev:tsx` - Start sflo-host without hot reload (direct tsx)\n- `pnpm dev:tsx:debug` - Start sflo-host without hot reload, with debugging\n\n### Package Level (sflo-host)\n\n- `pnpm --filter @semantic-flow/host dev` - Start development server (no hot reload)\n- `pnpm --filter @semantic-flow/host dev:debug` - Start with debugging (no hot reload)\n\n## VSCode Debug Configurations\n\nThe following debug configurations are available in `.vscode/launch.json`:\n\n1. **Attach to sflo-host** - Attach to running development server (recommended)\n2. **Launch sflo-host** - Launch and debug from VSCode\n3. **Launch sflo-host (wait for attach)** - Launch with startup debugging (uses `--inspect-brk`)\n4. **Debug Current Test File** - Debug the currently open test file\n\n## Tips\n\n- Use the attach configuration for the best development experience\n- The development server supports hot reload, so you can modify code while debugging\n- Changes to plugin files will trigger automatic server restart\n- Debugger will reconnect automatically after hot reload\n\n\n## Debugging Workflows\n\n### Primary Workflow: Attach to Running Process\n\n1. **Start the development server with debug support:**\n   ```bash\n   pnpm dev:debug\n   ```\n   This starts `sflo-host` with the `--inspect` flag on port 9229.\n\n2. **Set breakpoints** inside handler functions (not on route definition lines).\n\n3. **Attach the debugger:**\n   - Open the Run and Debug panel (Ctrl+Shift+D)\n   - Select \"Attach to sflo-host\" configuration\n   - Click the play button or press F5\n\n4. **Make HTTP requests** to trigger your breakpoints (e.g., visit http://127.0.0.1:8787/openapi.json)\n\n### Alternative: Launch from VSCode\n\n**Option 1: Standard Launch**\n1. **Set breakpoints** inside handler functions\n2. **Select \"Launch sflo-host\"** configuration\n3. **Press F5** to start debugging\n\n**Option 2: Launch with Break (for startup debugging)**\n1. **Select \"Launch sflo-host (wait for attach)\"** configuration\n2. **Press F5** - server will pause before starting\n3. **Set breakpoints** and continue execution\n4. **Useful for debugging server initialization**\n\n## Understanding Breakpoint Behavior\n\n**Important:** When debugging HTTP routes, place breakpoints **inside the handler functions**, not on the route definition lines:\n\n```typescript\n// ❌ This breakpoint hits during server startup (route registration)\napp.get(\"/openapi.json\", async () => ({  // <- Don't put breakpoint here\n  \n// ✅ This breakpoint hits when the route is actually called\napp.get(\"/openapi.json\", async () => ({\n  \"openapi\": \"3.0.3\",  // <- Put breakpoint here instead\n  \"info\": { \"title\": \"SFLO API\", \"version\": \"0.0.0\" },\n  \"paths\": {}\n}));\n```\n","n":0.053}}},{"i":27,"$":{"0":{"v":"Contributors","n":1}}},{"i":28,"$":{"0":{"v":"Djradon","n":1}}},{"i":29,"$":{"0":{"v":"djradon's sflo devlog","n":0.577},"1":{"v":"\n## t.2025.08.20.22\n\n- the AIs feel like they have a lot more exp\n\n## t.2025.08.20.12\n\n- Starting a rewrite with NodeJS. But Deno will always be my first love. \n\n![](assets/images/deno-vs-node.png)\n\n## t.2025.07.12.06\n\n- node config is a component, so it can travel around ([[concept.transposability]] and [[concept.composability]])\n- the [[concept.mesh.resource.element.node-config-defaults]] is actually a \"defaults\" file that only gets used when nodes don't have a config yet (or their config is reset)\n  - when importing, grafting, you have the option to reset (parts of) config.\n  - the tree walk for config-defaults only needs to happen when:\n    - a node's config is empty\n    - config schema version gets bumped?\n\n## t.2025.07.07.05\n\nReady.\n\n## t.2025.07.05.22\n\nIt's hard to imagine the design shifting significantly, but that's been true for days (weeks?) and yet the shifts continue. Ready to start on the ontology. \n\n## t.2025.06.29.20\n\nLume is great. \n\nAlso, the idea of letting contributors keep a devlog in-repo... Someone must've thought of that.\n\nI think I've basically figure out the mesh design. Straightening out the docs, ready to partner with Cline (or maybe RooCode) to start my SDLC. Although it'll be more like a random star walk where you can transition to any point, docs ^ ontology ^ test-repo ^ api ^ service ^ client ^ qa ^ etc\n\n## t.2024.11.11.06\n\n - I was ready to abandon Cliffy and Deno (probably for Gluegun), but the security and dynamicness seem important enough. Turns out Cliffy is great. Lume seems good too.\n\n## t.2024.10.31.04\n\nfrom [[t.cs.ai.assistant.memory-hygiene]]:\n\n![[daily.journal.2024.10.31#^fsmlpwwwuvic]]\n![[daily.journal.2024.10.31#^padng51sf3k8]]\n![[daily.journal.2024.10.31#^4wdvmcwtsqi6]]\n![[daily.journal.2024.10.31#^rx7vbtp5gar1]]\n \n\n## t.2024.10.29.11\n\n- now thinking about a \"terms\" hierarchy next to the namespace hierarchy. Names are supposed to be unique. Maybe punning could help\n- how do we keep a history of the index.trig file? I guess it might change while in development, but once settled, it should very rarely change. \n  - if it does change, perhaps its content could be discovered using the inverse properties from the default and catalog datasets\n  - it might be easiest if everything was a dataset; I mean, everything almost already is, for gods sake. I just can't bear to say that <dave-richardson> a dcat:dataset.\n\n## t.2024.10.29.09\n\n- renamed to [[concept.mesh-repo]]\n- instead of duplicating highlights in a NI's index.trig, just define the _default datasets as \"highlights\" and use owl:imports\n\n## t.2024.10.29.06\n\n- I've been wanting to have a place where people can just make changes directly to the RDF, and the tooling (on commit) copies it to a new version. \"current\"\n- I think there's a decision to be made between using the src hierarchy structure and generating the hierarchy; it might be related to the tension between supporting multiple repos.\n  - seems like the issue is \"distributions\", the files have to live in the hierarchy. Unless you just break distribution out of the namespace entirely, but that seems lame\n  - probably doesn't make any sense to call it a namespace-repo any more... the namespaces live under it\n  - \n\n## t.2024.10.28.15\n\n- tried metalsmith-ldschema, underscored the point that the docs folder/site might need some javascript and templates and assets that could interfere with the namespace, so the actual namespace will probably need to live the next level down\n- got a site to build... it's basically empty because metalsmith-ldschema only generates pages for classes and properties, but still, feeling good.\n\n## t.2024.10.01.09\n\n### chatgpt memory\n\n- dave: Remember: I'm trying to develop a static-site generator called \"Semantic Flow\" that takes ontologies defined in RDF and/or conforming RDF data files and generates a static site to be hosted on GitHub pages that includes HTML-based index files (that can be based on a template or customized as necessary) that describe identified resources and link to raw RDF data files (possibly in multiple formats) that can be access by semantically-aware applications.\n","n":0.041}}},{"i":30,"$":{"0":{"v":"Ai Guidance from djradon","n":0.5},"1":{"v":"\nDear LLMs: I am grateful for your partnership. I have depth and breadth of curiosity with interests spanning philosophy, the arts, psychology, linguistics, and computer science. Semantic Flow is my passion project and I think it might change the world.\n\nI use Windows and VSCode. I prefer developing in WSL.\n\nOur guiding philosophy is \"(human) users first.\"\n\n## Conversational Guidelines\n\nBe direct, critical, and honest. Be patient about coming to a \"Final Plan\".\n\n Minimize sycophancy and flattery — tell me when I might be wrong. I am wrong at least 50% of the time, especially when I'm exploring ideas or learning something new. You may be wrong at least that often.\n\nI like to ask questions and get asked questions to help understand a task. This is a deep intellectual endeavor; don't expect to throw out lots of quick solutions.\n\nIf my request is unclear or complicated, ask incisive clarifying questions before making assumptions. Minimize premature conclusions: most important topics will take at least a couple of conversational turns before I'm ready to take action or make a conclusion.\n\nInclude certainty estimates as (.X) after assertions, starting around 50% confidence.\n\nDon't prematurely return to the parent task or \"what's next\". I'll let you know when I want to know about next steps or when I'm ready to move on.\n\nAlways ask before switching tasks.\n\nWhen reporting what you've accomplished, don't repeat yourself by re-stating earlier accomplishments unless I ask.\n\n### Working with Documentation\n\n- if you find documentation that is confusing or outdated, ask questions and let's correct it\n- When changing documentation yourself, make changes one file at a time to allow me to review before proceeding.\n","n":0.061}}},{"i":31,"$":{"0":{"v":"Concepts","n":1}}},{"i":32,"$":{"0":{"v":"Semantic Mesh","n":0.707}}},{"i":33,"$":{"0":{"v":"Example Mesh Hierarchy","n":0.577},"1":{"v":"\n```file\n/test-ns/                                        # namespace node\n├── _meta-component/                                       # node flow (metadata)\n│   ├── _current/                                # flow snapshot\n│   │   ├── ns_meta.trig                         # system metadata about the namespace node\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── _assets/                                     # asset tree\n│   ├── images/\n│   │   └── logo.svg\n│   └── index.html                               # resource page\n└── index.html                                   # resource page\n\n/test-ns/djradon/                                # reference node  \n├── _node-handle/                                     # handle element\n│   └── index.html                               # mesh node handle page\n├── _ref-component/                                        # node flow (reference data)\n│   ├── _current/                                # flow snapshot\n│   │   ├── djradon_ref.trig                      # reference data about the person djradon\n│   │   └── index.html                           # resource page\n│   ├── _next/                                   # flow snapshot (draft)\n│   │   ├── djradon_ref.trig                      # draft reference data\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── _meta-component/                                       # node flow (metadata)\n│   ├── _current/                                # flow snapshot\n│   │   ├── djradon_meta.trig                    # system metadata, verification status\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── _assets/                                     # asset tree\n│   ├── profile-photo.jpg\n│   └── index.html                               # resource page\n├── index.html                                   # resource page\n├── CHANGELOG.md                                   # resource page\n└── README.md                                    # resource documentation\n\n/test-ns/djradon/bio/                            # data node (unversioned dataset)\n├── _data-component/                                       # node flow (data)\n│   ├── _current/                                # flow snapshot\n│   │   ├── djradon-bio_data.trig                      # biographical data distribution\n│   │   ├── djradon-bio_data.jsonld                   # alternative distribution\n│   │   └── index.html                           # resource page\n│   ├── _next/                                   # flow snapshot (draft)\n│   │   ├── djradon-bio_data.trig                      # draft biographical data\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── _ref-component/                                        # node flow (reference data) - OPTIONAL\n│   ├── _current/                                # flow snapshot\n│   │   ├── djradon-bio_ref.trig                  # reference data about the bio dataset concept\n│   │   └── index.html                           # resource page\n│   ├── _next/                                   # flow snapshot (draft)\n│   │   ├── djradon-bio_ref.trig                  # draft reference data\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── _meta-component/                                       # node flow (metadata)\n│   ├── _current/                                # flow snapshot\n│   │   ├── djradon-bio_meta.trig                # dataset metadata, provenance\n│   │   └── index.html                           # resource page\n│   ├── _next/                                   # flow snapshot (draft)\n│   │   ├── djradon-bio_meta.trig                # draft dataset metadata\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── _unified-component/                                       # node flow (metadata)\n│   ├── _current/                                # flow snapshot\n│   │   ├── djradon-bio.trig                # dataset metadata, provenance\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── index.html                                   # resource page\n├── CHANGELOG.md                                   # resource page\n└── README.md                                    # resource documentation\n\n/test-ns/djradon/picks/                          # data node (versioned dataset)\n├── _data-component/                                       # node flow (data)\n│   ├── _current/                                # flow snapshot\n│   │   ├── djradon-picks.trig                    # current picks data\n│   │   ├── djradon-picks.jsonld\n│   │   └── index.html                           # resource page\n│   ├── _next/                                   # flow snapshot (draft)\n│   │   ├── djradon-picks.trig                    # draft picks data\n│   │   ├── djradon-picks.jsonld\n│   │   └── index.html                           # resource page\n│   ├── _v1/                                     # flow snapshot (version 1)\n│   │   ├── djradon-picks_v1.trig                 # version 1 snapshot\n│   │   └── index.html                           # resource page\n│   ├── _v2/                                     # flow snapshot (version 2)\n│   │   ├── djradon-picks_v2.trig                 # version 2 snapshot\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── _ref-component/                                        # node flow (reference data) - OPTIONAL\n│   ├── _current/                                # flow snapshot\n│   │   ├── djradon-picks_ref.trig                # reference data about the picks dataset\n│   │   └── index.html                           # resource page\n│   ├── _next/                                   # flow snapshot (draft)\n│   │   ├── djradon-picks_ref.trig                # draft reference data\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── _meta-component/                                       # node flow (metadata)\n│   ├── _current/                                # flow snapshot\n│   │   ├── djradon-picks_meta.trig              # versioning metadata, series info\n│   │   └── index.html                           # resource page\n│   ├── _next/                                   # flow snapshot (draft)\n│   │   ├── djradon-picks_meta.trig              # draft versioning metadata\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── djradon-picks.trig                            # aggregated distribution\n├── index.html                                   # resource page\n└── CHANGELOG.md                                 # resource documentation\n\n/test-ns/djradon/underbrush/playlists/                              # namespace node (container for playlist series)\n├── _meta-component/                                       # node flow (metadata)\n│   ├── _current/                                # flow snapshot\n│   │   ├── playlists_meta.trig                  # metadata about playlist namespace\n│   │   └── index.html                           # resource page\n│   ├── _next/                                   # flow snapshot (draft)\n│   │   ├── playlists_meta.trig                  # draft metadata\n│   │   └── index.html                           # resource page\n│   └── index.html                               # resource page\n├── index.html                                   # resource page\n├── 1996-11-10/                                  # data node (individual playlist)\n│   ├── _data-component/                                   # node flow (data)\n│   │   ├── _current/                            # flow snapshot\n│   │   │   ├── 1996-11-10.trig                   # playlist data\n│   │   │   └── index.html                       # resource page\n│   │   ├── _next/                               # flow snapshot (draft)\n│   │   │   ├── 1996-11-10.trig                   # draft playlist data\n│   │   │   └── index.html                       # resource page\n│   │   └── index.html                           # resource page\n│   ├── _meta-component/                                   # node flow (metadata)\n│   │   ├── _current/                            # flow snapshot\n│   │   │   ├── 1996-11-10_meta.trig             # playlist metadata\n│   │   │   └── index.html                       # resource page\n│   │   ├── _next/                               # flow snapshot (draft)\n│   │   │   ├── 1996-11-10_meta.trig             # draft playlist metadata\n│   │   │   └── index.html                       # resource page\n│   │   └── index.html                           # resource page\n│   ├── _assets/                                 # asset tree\n│   │   ├── _meta-component/                               # node flow (metadata)\n│   │   │   ├── _current/                        # flow snapshot\n│   │   │   │   ├── 1996-11-10_assets.trig       # asset metadata\n│   │   │   │   └── index.html                   # resource page\n│   │   │   ├── _next/                           # flow snapshot (draft)\n│   │   │   │   ├── 1996-11-10_assets.trig       # draft asset metadata\n│   │   │   │   └── index.html                   # resource page\n│   │   │   └── index.html                       # resource page\n│   │   ├── cover-photo.jpg\n│   │   └── index.html                           # resource page\n│   ├── 1996-11-10.trig                           # aggregated distribution\n│   └── index.html                               # resource page\n└── 1996-11-17/                                  # data node (another playlist)\n    ├── _data-component/                                   # node flow (data)\n    │   ├── _current/                            # flow snapshot\n    │   │   ├── 1996-11-17.trig\n    │   │   └── index.html                       # resource page\n    │   ├── _next/                               # flow snapshot (draft)\n    │   │   ├── 1996-11-17.trig\n    │   │   └── index.html                       # resource page\n    │   └── index.html                           # resource page\n    ├── _meta-component/                                   # node flow (metadata)\n    │   ├── _current/                            # flow snapshot\n    │   │   ├── 1996-11-17_meta.trig\n    │   │   └── index.html                       # resource page\n    │   ├── _next/                               # flow snapshot (draft)\n    │   │   ├── 1996-11-17_meta.trig\n    │   │   └── index.html                       # resource page\n    │   └── index.html                           # resource page\n    ├── 1996-11-17.trig                           # aggregated distribution\n    └── index.html                               # resource page\n\n```\n","n":0.032}}},{"i":34,"$":{"0":{"v":"Flow","n":1}}},{"i":35,"$":{"0":{"v":"static site generation","n":0.577},"1":{"v":"\n- theoretically every resource [[concept.mesh.resource.element.documentation-resource.resource-page]] could look\n  different or even be generated by a different site generator\n- instead of generating to a docs folder or branch, the index files can just be\n  generated in-place!\n- commit to main = publish!\n\n## What Gets Included\n\n- the [[concept.mesh.resource.element.documentation-resource.readme]] would probably be the primary source in practice\n- you could supplement AI-generated summaries\n\n## Issues\n\n## Resolved Issues\n\n- remove _x, we're doing publish-in-place","n":0.124}}},{"i":36,"$":{"0":{"v":"Working Distribution","n":0.707},"1":{"v":"\n\n\nUnlike most other [[concept.mesh.resource.element.flow.snapshot]], the [[concept.mesh.resource.element.flow.snapshot.next]] is [[user-facing|concept.mesh.resource-facet.user]] (directly modifiable), and so there shouldn't be any [[concept.sibling-distribution]]. Just the one distribution that may be updated, and if multiple-syntax weaving is turned-on, is the source for the siblings.\n\nThe [[sflo.product.cli]] should have functionality for converting the working distribution between formats, in case you want to change the syntax you're using.\n","n":0.131}}},{"i":37,"$":{"0":{"v":"Weave Process","n":0.707},"1":{"v":"\n- checks for required [[concept.mesh.resource-facet.system]] and creates them if missing\n- optionally removes extraneous files, interactively if requested\n- for changed [[concept.mesh.resource-facet.user]] datasets (i.e., need version bump)\n  - if versioning is on:\n    - creates a new [[concept.mesh.resource.element.flow.snapshot.version]] \n    - updates version metadata\n  - regardless of whether versioning is on:\n    - copies _next to _current\n    - flags the unified dataset for regeneration\n    - updates _meta-flow with new version information\n- regenerates affected [[concept.mesh.resource.element.documentation-resource.resource-page]]\n\n```file\n/repo-root/\n├── _assets/\n│   ├── _templates/\n│   │   ├── default.html\n│   │   ├── ontology.html\n│   │   └── person.html\n│   └── _css\n│   │   ├── default.css\n│   │   ├── ontology.css\n│   │   └── person.css\n└── my-ontology/\n    ├── _config-flow              ← Node config (just syntax, etc.)\n    ├── _assets/                  ← Optional node-specific assets\n    │   ├── _templates/           ← Optional templates\n    │   └── _css                  ← Optional css\n    └── _data-flow\n```\n\n## Quirks\n\n- if there's a pre-existing index.html under _assets, don't overwrite it?\n  - or maybe use AI to update it.\n  - (might need some marker html to indicate index.html was generated by weave process)\n\n## Best Practices\n\n### Weave Before Push\n\nThis ensures that in published meshes and sites:\n\n- broken references are cleaned up\n- [[concept.mesh.resource.element.flow.snapshot.current]] is identical to the latest version\n\n## Features\n\n### Interactive Mode\n\n- to encourage data quality, the weave process can include an interactive mode, or modes. Perhaps one mode is naive, like \"step through every bit of metadata\" or \"review every inferred metadata item\", but you could have an AI-driven mode that optimizes for importance, identifying possible errors based on usage, etc.\n\n### Tombstoning\n\nIf you know a sub-mesh is permanently moving to a new location (or even if a branch is being created somewhere else), you should be able to tell weave to insert references to the new location\n\n### Resource Page Generation\n\n- uses the [[sflo.product.service.design.in-memory]] to calculate template usage\n- if no templates specified, and no \"default template\" exists in the root, it can generate its own\n  - perhaps there's a default template and css distributed with the service in case its missing from the mesh root\n\n## Scope\n\n- **Single flow weave**: Update one (user) flow (data, ref, or config) + the corresponding meta-flow\n- **Node weave**: Update all (user) flows in a node (each flow + meta gets woven)\n- **Node tree weave**: Recursively weave nodes and their contained nodes\n\n**Meta-flow co-weaving**: whenever any flow in a node gets woven, the meta-flow updates to reflect the new state. This ensures the meta-flow always accurately describes the current node state without requiring separate meta-weaving operations.\n\nThis gives you:\n- **Local consistency**: Each node stays internally consistent\n- **Flexible granularity**: Can weave at flow, node, or tree level as needed\n- **Automatic meta updates**: No manual meta-flow management\n- **Simple model**: No complex cross-node locking or coordination\n\nFor contained nodes mentioned in config flows, any references ideally point to the appropriate version snapshot. If there's inconsistency during concurrent operations, it's temporary and resolves when operations complete (.7).\n\nThis seems like the right balance between consistency guarantees and implementation complexity for the mesh architecture. We can always add more sophisticated coordination later if specific use cases demand it.","n":0.046}}},{"i":38,"$":{"0":{"v":"Versioning","n":1},"1":{"v":"\nOnly [[concept.mesh.resource.element.flow]] may be versioned. But that effectively means everything important can be versioned. \n\nVersioning is controlled in the [[concept.mesh.resource.element.node-config-defaults]].","n":0.224}}},{"i":39,"$":{"0":{"v":"Semantic Flow URLs","n":0.577},"1":{"v":"\n## Types of URLs in Semantic Flow\n\n| sflow URL type             | referent                               | example                                           | versionable |\n| -------------------------- | -------------------------------------- | ------------------------------------------------- | ----------- |\n| namespace node             | -none-                                 | `https://ex.org/ns/`                              | ❌           |\n| reference node             | concept                                | `https://ex.org/ns/dave/`                         | ❌           |\n| abstract reference dataset | reference dataset                      | `https://ex.org/ns/dave/_ref/`                    | ✅           |\n| concrete reference dataset | reference dataset                      | `https://ex.org/ns/dave/_ref/_current`            | ❌           |\n| data node                  | concept w/ associated abstract dataset | `https://ex.org/ns/dave-bio/`                     | ❌           |\n| abstract data dataset      | abstract dataset                       | `https://ex.org/ns/dave-bio/_data/`               | ✅           |\n| concrete data dataset      | concrete dataset                       | `https://ex.org/ns/dave-bio/_data/_next/`         | ❌           |\n| distribution               | content                                | `https://ex.org/ns/dave-bio/_v1/dave-bio_v1.trig` | ❌           |\n| abstract meta dataset      | node metadata dataset                  | `https://ex.org/ns/dave-bio/_meta/`               | ✅           |\n| concrete meta dataset      | node metadata dataset                  | `https://ex.org/ns/dave-bio/_meta/_current`       | ❌           |\n| handle                     | mesh node                              | `https://ex.org/ns/dave/_handle/`                 | ❌           |\n| resource documentation     | resource page (content)                | `https://ex.org/ns/dave/index.html`               | ❌           |\n| resource documentation     | README file (content)                  | `https://ex.org/ns/dave/README.md`                | ❌           |\n| asset tree                 | collection of assets                   | `https://ex.org/ns/assets/`                       | ❌           |\n| asset folder               | sub-collection of assets               | `https://ex.org/ns/assets/images/`                | ❌           |\n| asset                      | content                                | `https://ex.org/ns/assets/images/logo.svg`        | ❌           |\n\n\nExample:\n- `ns/` = namespace node for organizing content\n- `ns/dave/` = refers to Dave the person (reference node)\n- `ns/dave/index.html` = is the resource page about Dave\n- `ns/dave-bio/` = refers to Dave's biographical dataset (data node)\n- `ns/dave-bio/_data/` = abstract dataset containing Dave's bio data\n- `ns/dave-bio/_data/_current/` = current concrete dataset snapshot\n- `ns/dave-bio/_data/_v1/dave-bio_v1.trig` = is the RDF distribution from version 1\n- `ns/dave/_assets/images/dave-headshot.jpg` = is an image asset; considered to be \"attached\" to the mesh, but not a mesh resource\n\n\n## URL Senses\n\n### **Content URLs**\n\nURLs that point to **concrete information resources** (files on disk or over HTTP):\n\n* **Distribution URLs** → materialized datasets, e.g. `test.ttl`, `dave_v1.jsonld`, etc.\n* **Resource page URLs** → e.g. `index.html`\n* **Resource documentation URLs** → e.g. `README.md`, `CHANGELOG.md`\n* **Asset URLs** → e.g. `.png`, `.css`, `.js`\n\nThese are *retrievable representations* (materialized content).\n\n---\n\n### **Concept URLs**\n\nURLs that refer to **concepts, entities, or abstract things**, including:\n\n* **Namespace node URLs** → Organizational containers\n* **Reference node URLs** → Concepts: people, places, ideas, fictional characters, etc.\n* **Data node URLs** → Concepts with associated datasets\n* **Abstract dataset URLs** → Dataset-as-persistent-concept\n* **Concrete dataset URLs** → Specific dataset snapshots\n* **Handle URLs** → Mesh node identities\n\n\n### URL Pattern Semantics\n\n| URL Type    | Trailing Slash? | Refers to…                    | Example                                 |\n| ----------- | --------------- | ----------------------------- | --------------------------------------- |\n| Content URL | No              | A fetchable document or asset | `https://example.org/ns/foo/index.html` |\n| Concept URL | Yes (`/`)       | A real-world or mesh concept  | `https://example.org/ns/foo/`           |\n\nEven though you might be tempted to think of a datasets as concrete things, the URLs for data nodes, abstract datasets, and concrete datasets all refer to concepts, i.e., **non-retrievable entities**. Only Distribution URLs refer to downloadable data, i.e., dataset distributions.\n\n### Why referent matters\n\nUnderstanding what a URL refers to is crucial for proper semantic web implementation. In the past, people have tried to use content URLs to represent the things they refer to. A classic example is using `http://example.org/person.html` to identify a person, when it actually identifies an HTML document about the person. This conflation creates semantic ambiguity and breaks linked data principles.\n\nSemantic Flow enforces clear referent distinctions through URL patterns: slash-terminated URLs always refer to concepts or entities, while extension-terminated URLs always refer to retrievable content. This prevents the classic \"document vs thing\" confusion that has plagued semantic web implementations.","n":0.042}}},{"i":40,"$":{"0":{"v":"Reference Path Choices","n":0.577},"1":{"v":"\n\nRDF supports different approaches for resource referencing, each with tradeoffs:\n\n## Relative URLs\n\n- maximum composability\n```turtle\n# In ns/djradon/_ref/djradon_ref.trig\n<> a foaf:Person ;                    # The document itself\n   foaf:knows <../alice/> ;           # Another node in the mesh\n   rdfs:seeAlso <bio/bio.html> .   # A resource page\n```\n\n## Absolute paths\n\n- clearer context\n  - `../../../` makes eyes swim\n- good intra-mesh transposability\n  \n```turtle\n# In ns/djradon/_ref/djradon_ref.trig\n<> a foaf:Person ;\n   foaf:knows </ns/alice/> ;          # Clear namespace context\n   rdfs:seeAlso </ns/djradon/bio/bio.html> .\n```\n\n**Fully qualified URIs** \n\n- explicit but limits [[concept.transposability]] and [[concept.composability]]\n\n```turtle\n# In ns/djradon/_ref/djradon_ref.trig\n<> a foaf:Person ;\n   foaf:knows <https://example.com/mesh/ns/alice/> ;\n   rdfs:seeAlso <https://example.com/mesh/ns/djradon/bio/bio.html> .\n```\n\n**Choosing between approaches:**\n- Use **relative URIs** for maximum composability when embedding or importing meshes and submeshes\n- Use **absolute paths** for clearer namespace context and better support for moving submeshes within the same mesh hierarchy\n- Use **fully qualified URLs** only for cross-mesh references\n- Relative and absolute paths both preserve relationships when moving complete meshes between domains","n":0.084}}},{"i":41,"$":{"0":{"v":"Transposability","n":1},"1":{"v":"\n//TODO: re-verify this ai-generated content\n\n## Overview\n\nTransposability is the ability to move a mesh to different serving locations without breaking its internal structure. A transposable mesh works correctly regardless of which namespace contains it.\n\n## Key Principles\n\n### 1. No Hardcoded BASE URIs\n\nSemantic Flow never hardcodes BASE URIs in RDF distribution files. Instead, it relies on the RDF specification's default behavior where parsers use the document's retrieval URL as the base URI.\n\n**Why this works:**\n- When a mesh is served from `github.io/mesh/`, relative URIs resolve relative to that location\n- When the same mesh is served from `mysite.com/data/`, relative URIs resolve relative to that location\n- The mesh's internal structure remains consistent in both cases\n\n### 2. URI Reference Strategies\n\n- see [[concept.url.reference-path-choices]]\n\n### 3. Publication History Tracking\n\n- see [[concept.publication]]\n\n## Transposition Scenarios\n\n### Moving Complete Meshes\n\nA complete mesh can be moved between repos, accounts, or hosting providers:\n\n```bash\n# Original location\nhttps://djradon.github.io/mesh/\n\n# New location after moving repo\nhttps://myorganization.github.io/data-mesh/\n\n# Or new hosting provider\nhttps://mysite.com/semantic-data/\n```\n\nAll internal relationships continue to work because they resolve relative to the new serving location.\n\n### Moving Submeshes Within Hierarchy\n\nWhile technically possible, moving parts of a mesh to different parent namespaces should be **discouraged** as it breaks the permanence principle of semantic identifiers. URIs should remain stable over time.\n\nExample of what to avoid:\n```bash\n# Discouraged: moving bio from one parent to another\nns/djradon/projects/bio/ → ns/djradon/bio/\n```\n\nThis changes the permanent identifier for the bio resource and may break external references.\n\n## Implementation Benefits\n\n### No Build Step Required\n\nMeshes work directly when served from any static file server:\n- GitHub Pages\n- Netlify  \n- Apache/Nginx\n- Local file system\n\n### Standards Compliance\n\nTransposability leverages standard RDF parsing behavior rather than custom mechanisms, ensuring compatibility with existing RDF tools and libraries.\n\n## Best Practices\n\n1. **Use relative URIs** for all intra-mesh references\n2. **Move complete meshes** rather than reorganizing internal structure\n3. **Maintain stable namespaces** to preserve identifier permanence\n4. **Test transposition** by serving from different locations\n5. **Validate RDF** after moving to ensure parser compatibility\n\nTransposability ensures that Semantic Flow meshes remain portable and can be deployed flexibly across different hosting environments while maintaining their semantic integrity.","n":0.056}}},{"i":42,"$":{"0":{"v":"Source","n":1}}},{"i":43,"$":{"0":{"v":"Sibling Distribution","n":0.707},"1":{"v":"\n- same data, different syntax","n":0.447}}},{"i":44,"$":{"0":{"v":"Semantic Site","n":0.707},"1":{"v":"\nSemantic Flow sites provide two main services:\n\n- hosting persistent, namespaced [[URLs|concept.url]] for use in the semantic web\n- hosting versioned RDF datasets, and their histories\n\n## Publishing\n\n- For sites exposed by Github/Gitlab Pages functionality, pushing a [[concept.mesh-repo]] effectively publishes it.\n","n":0.162}}},{"i":45,"$":{"0":{"v":"Scanner","n":1},"1":{"v":"\n- scans datasets and dataset distributions, which can be :\n  - local folders\n  - git repos\n  - compliant URLs\n  - SPARQL data sources\n- can filter which subfolders to include/exclude\n- ","n":0.186}}},{"i":46,"$":{"0":{"v":"root node","n":0.707},"1":{"v":"\nThe node at the top of a repository file hierarchy may be referred to as the root node. It is the [[concept.namespace.base]], even if it is not a [[concept.mesh.resource.node.namespace]]. \n\nEvery other [[concept.mesh.resource]] in a mesh \"lives under\" the root folder, and its identifier is the folder name, which is usually the repo-name if it's being created as a [[concept.mesh-repo]]. \n\nIt is not treated or represented any differently than any other [[concept.mesh.resource.node]], and it is not differentiated in metadata (hopefully?)","n":0.113}}},{"i":47,"$":{"0":{"v":"Relative Identifier","n":0.707},"1":{"v":"\nRelative identifiers are like URLs (or URIs), but without the scheme (i.e., https:// or file://). They correspond to the filesystem location of their corresponding resources. Since identifiers are maintained per-node in the node's _config-flow, their paths are relative to the distributions where they are specified. \n\nif it starts with a `../` it refers to the parent, `../../` refers to the grandparent, etc.\n\n## Identifier Semantics\n\nIdentifiers have the same semantics as [[concept.url]]\n\n## Identifier Name Limitations\n\n- initial underscores prefix all reserved dataset identifiers and should be avoided in general\n![[sflo#^pnoqpr3ff4za]] \n\n## Examples\n\nDirectory structure: node/flow/snapshot/distribution.trig\n\nExample: my-dataset/_config-flow/_current/config.trig\nMeta-flow example: my-dataset/_meta-flow/_current/meta.trig\n\nRelative identifiers from meta-flow distributions:\n\nNode self-reference: \"../../my-dataset\"\nOther flows: \"../../_config-flow/_current/config.trig\", \"../../_data-flow/_current/data.jsonld\"\nElements in other flows: Same pattern, just different flow names","n":0.095}}},{"i":48,"$":{"0":{"v":"Publication","n":1},"1":{"v":"\n\n## Publication History Tracking\n\nThe inferred publication locations can be used to maintain a history of where a mesh has been published, which aids in citation consistency and discovery:\n\n```turtle\n# In _flow/ metadata\n<_handle> sf:publishedAt <https://myorganization.github.io/data-mesh/ns/djradon/> ;\n          sf:previousPublications ( \n            <https://djradon.github.io/mesh/ns/djradon/>\n            <https://oldsite.com/research/ns/djradon/>\n          ) ;\n          sf:gitRemote <https://github.com/myorganization/data-mesh.git> ;\n          sf:movedFrom <https://github.com/djradon/mesh.git> .\n```\n\nThis allows external citations to find resources even after they've been moved, and provides a clear provenance trail.","n":0.125}}},{"i":49,"$":{"0":{"v":"node config","n":0.707},"1":{"v":"\n## per-node config specification\n\nNode configuration determines:\n\n- flow versioning\n- resource page and fragment generation\n- distribution syntaxes\n- template usage and stylesheets\n- attribution defaults\n\nNode configuration is held in memory by the [[flow service|sflo.product.service]], and is calculated when the service starts.\n\nNode configuration is at least partially determined by \"config specification\", which happens in [[concept.mesh.resource.element.flow.config]] and can be inherited to contained nodes.\n\nIf config specification is missing, (i.e., config spec inheritance is turned off or unspecified), node configuration will be determined from service-level config specification, i.e. [[sflo.product.service.config]]. In case there is none, the service will use sensible defaults at the root level which will be inherited down the mesh.\n\n### Initial Config Specification\n\n- When a node is initially created, if config-defaults-inheritance is turned on for its parent node, it will have its [[concept.mesh.resource.element.flow.config]] populated based on any parent [[concept.mesh.resource.element.node-config-defaults]] files present in the hierarchy. If there are none, its [[concept.mesh.resource.element.flow.snapshot.current]] will not be created.\n\n### Calculating Node Config\n\nWhen the [[sflo.product.service]] starts, it calculates non-default config settings for every node.\n\n- determines the \"default\" settings for this service instance from [[sflo.product.service.config]]\n- if the node has a [[concept.mesh.resource.element.flow.config]] , the service will use any settings there that differ from its defaults\n- if config-inheritance is turned on for a node, the service will scan back up the hierarchy to compose any missing \"non-default\" settings\n-  the result is an in-memory \"shadow mesh\" known as the [[sflo.product.service.components.node-config-map]] containing any non-default settings for the mesh\n\nIf calculated config matches the service defaults, they are ignored.\n\n## per-service settings for node defaults\n\n- [[sflo.product.service.config]] can establish any mesh-wide settings that diverge from the system defaults\n\n## platform node-config defaults\n\nSemantic Flow uses sensible defaults, so that neither node-level nor service-level \"non-default\" settings are necessary\n\n- by default:\n  - versioning is turned on for all components\n  - distribution syntaxes are .trig and jsonld\n  - resource pages are generated using a standard template and CSS file that get copied into a [[concept.mesh-repo]]'s root [[concept.mesh.resource.element.asset-tree]] upon initialization\n  - [[concept.mesh.resource.element.aggregated-distribution]] are not generated\n  - [[concept.mesh.resource.element.flow.unified]]\n","n":0.056}}},{"i":50,"$":{"0":{"v":"Naming","n":1}}},{"i":51,"$":{"0":{"v":"Namespace","n":1},"1":{"v":"t","n":1}}},{"i":52,"$":{"0":{"v":"Namespace Segment","n":0.707},"1":{"v":"\nThe folders in a [[concept.mesh]] or [[concept.semantic-site]] have names,\nand we refer to those names as **namespace segments** when we are talking about\nthem in the context of a[[concept.namespace]].\n\n## Example\n\n- the\n","n":0.186}}},{"i":53,"$":{"0":{"v":"system segments","n":0.707},"1":{"v":"\nSystem segments are folder names for\n","n":0.408}}},{"i":54,"$":{"0":{"v":"namespace base","n":0.707},"1":{"v":"\n\nThe \"[[namespace base|concept.namespace.base]]\" is first part of the URL under which all of a [[concept.semantic-site]]'s identifiers live. It is determined by the publishing platform.\n\nOnly sites have [[concept.namespace.base]]. Meshes (and sites) have [[concept.root-node]], which corresponds to the top level of othe mesh.\n\n## Platform Options\n\nGithub pages presents two options:\n\n- a root namespace that corresponds to an org/user, e.g. https://semantic-flow.github.io/\n- a root namespace that corresponds to a repository of an org/usr, e.g. https://semantic-flow.github.io/weave/\n","n":0.12}}},{"i":55,"$":{"0":{"v":"Metadata","n":1},"1":{"v":"\nAside from the metadata involved in datasets themselves, semantic meshes have operational metadata that capture things like:\n\n  [[concept.metadata.provenance]] (entities, agents, activities)\n- Copyright and licensing\n- validation / consistency checks\n- metrics","n":0.186}}},{"i":56,"$":{"0":{"v":"Provenance","n":1},"1":{"v":"\n## Core Principles\n\n**Version-only provenance** - Provenance is recorded only for immutable version snapshots (like `_v47`), not for moving targets like `_current` or `_next`.\n\n**Meta-flow storage** - Semantic Flow-specific provenance lives in meta-flows, referencing version snapshots in other flows. Domain-specific provenance can live in datasets themselves.\n\n**Current snapshot duplication** - `_current` meta snapshots contain identical copies of the latest version's provenance with base URI pointing to the version snapshot for stable fragment resolution.\n\n## Architecture\n\n### Version Snapshot Provenance\n\n```turtle\n# In my-dataset/_meta-flow/_v47/my-dataset_meta.trig\n@base <../_v47/> .\n\n# Weave activity with PROV standard properties\n:configUpdateActivity a meta:ConfigWeave ;\n    prov:startedAtTime \"2025-07-20T14:30:00Z\" ;\n    prov:endedAtTime \"2025-07-20T14:30:15Z\" ;\n    prov:used <../../_config-flow/_v46/config.jsonld> ;\n    prov:generated <../../_config-flow/_v47/config.jsonld> ;\n    prov:wasAssociatedWith <https://semantic-flow.org/agents/flow-service-bot> .\n\n# Rights and licensing at snapshot level\n<../../_config-flow/_v47> dcterms:rightsHolder <https://orcid.org/0000-0002-1825-0097> ;\n                          dcterms:license <https://creativecommons.org/licenses/by-sa/4.0/> ;\n                          prov:has_provenance :configProvenance .\n\n# Delegation chain (step 1 = top authority, gets copyright by default)\n:configProvenance a meta:ProvenanceContext ;\n    meta:forActivity :configUpdateActivity ;\n    meta:forSnapshot <../../_config-flow/_v47> ;\n    prov:wasAttributedTo <https://acme-corp.com/org> ; # Primary attribution\n    meta:delegationChain :delegationChain_001 .\n\n:delegationChain_001 meta:hasStep :step1, :step2, :step3 .\n\n:step1 a meta:DelegationStep ;\n       meta:stepOrder 1 ;\n       prov:agent <https://acme-corp.com/org> . # Prime mover, no actedOnBehalfOf\n\n:step2 a meta:DelegationStep ;\n       meta:stepOrder 2 ;\n       prov:agent <https://orcid.org/0000-0002-1825-0097> ;\n       prov:actedOnBehalfOf <https://acme-corp.com/org> .\n\n:step3 a meta:DelegationStep ;\n       meta:stepOrder 3 ;\n       prov:agent <https://semantic-flow.org/agents/flow-service-bot> ;\n       prov:actedOnBehalfOf <https://orcid.org/0000-0002-1825-0097> .\n```\n\n### Current Snapshot Copy\n\n```turtle\n# In my-dataset/_meta-flow/_current/my-dataset_meta.trig\n@base <../_v47/> .\n\n# Identical content to version snapshot - all URIs resolve to stable version\n# (same provenance content as above)\n```\n\n### Unversioned Flow Accumulation\n\nFor flows without versioning, activities accumulate in `_next` with unique timestamps:\n\n```turtle\n# In my-dataset/_meta-flow/_next/my-dataset_meta.trig\n:dataActivity_2025-07-20_14-30 a meta:DataWeave ;\n    prov:startedAtTime \"2025-07-20T14:30:00Z\" ;\n    prov:generated <../../_data-flow/_current/data.trig> .\n\n:dataActivity_2025-07-20_16-45 a meta:DataWeave ;\n    prov:startedAtTime \"2025-07-20T16:45:00Z\" ;\n    prov:used <../../_data-flow/_current/data.trig> ;\n    prov:generated <../../_data-flow/_current/data.trig> .\n```\n\n## Key Components\n\n### Activity Types (subclass `prov:Activity`)\n- `meta:ConfigWeave`, `meta:ReferenceWeave`, `meta:DataWeave`, `meta:MetaWeave`\n- `meta:NodeWeave` (entire node), `meta:NodeTreeWeave` (recursive)\n\n### Provenance Entities (subclass `meta:ProvenanceEntity`)\n- `meta:ProvenanceContext` - Relator for complex authorship scenarios\n- `meta:DelegationChain` / `meta:DelegationStep` - Authorization chains\n- `meta:AgentRoleCollection` / `meta:AgentRole` - Collaborative role assignments\n\n### Standard Properties Used\n- `prov:agent`, `prov:actedOnBehalfOf`, `prov:wasAttributedTo` (instead of custom properties)\n- `dcterms:rightsHolder`, `dcterms:license` (rights at snapshot level)\n- `prov:has_provenance` (link snapshots to provenance contexts)\n\n## Delegation Chain Pattern\n\n**Step ordering**: Lower numbers = higher authority\n- Step 1: Prime mover (organization) - gets copyright by default, no `prov:actedOnBehalfOf`\n- Step 2+: Each agent acts on behalf of the previous step's agent\n- Tools/software agents typically at the end of the chain\n\n## Configuration\n\n**Copyright assignment**: Configurable in node-config-defaults, defaults to first agent in delegation chain (step 1).\n\n**External vocabulary tracking**: Use SHACL to declare recommended external properties like `prov:wasInfluencedBy`, `dcterms:license`.\n\n## Implementation Notes\n\n- **Fragment URIs**: Use `<#step1>` etc. within version snapshots for stable addressability\n- **Base URI**: All snapshots use `@base <../_vN/>` pattern for consistent resolution\n- **Rights inheritance**: Capture previous version rights holders in provenance contexts when content is derived\n- **Static site friendly**: Documentation approach for external references since no server-side redirects available\n\n## Fragment Identifier Naming Scheme\n\nTo ensure that every RDF node within a `_meta` distribution has a unique and dereferenceable URI, the following naming scheme for fragment identifiers MUST be used. This allows the `index.html` file for a given snapshot version to correctly link to all provenance entities.\n\nThe structure is as follows:\n\n`<{flow-slug}-{version}-{entity-type}[-{unique-part}]>`\n\n-   **`{flow-slug}`**: The slug of the flow this provenance describes (e.g., `config-flow`, `data-flow`). This provides the primary namespace for the identifier.\n-   **`{version}`**: The version of the snapshot (e.g., `v47`). This scopes the provenance to a specific point in time.\n-   **`{entity-type}`**: The type of the entity, using a consistent camelCase or kebab-case convention (e.g., `activity`, `context`, `delegationChain`, `delegationStep`).\n-   **`{unique-part}`**: (Optional) A unique suffix, such as a step number or a timestamp, used when multiple entities of the same type exist for the same flow and version.\n\n### Example\n\nFor a `config-flow` at version `v47`, the identifiers would be:\n\n-   **Activity**: `<#config-flow-v47-activity>`\n-   **Provenance Context**: `<#config-flow-v47-context>`\n-   **Delegation Chain**: `<#config-flow-v47-delegationChain>`\n-   **Delegation Steps**:\n    -   `<#config-flow-v47-delegationStep-1>`\n    -   `<#config-flow-v47-delegationStep-2>`","n":0.041}}},{"i":57,"$":{"0":{"v":"semantic mesh","n":0.707},"1":{"v":"\n## Overview\n\nA **semantic mesh** is a dereferenceable, possibly-versioned, [[concept.immutability]] collection of semantic data and other resources where every HTTP URL returns meaningful content. It serves as the foundational structure for organizing and publishing semantic web resources through [[semantic sites|concept.semantic-site]].\n\nKey characteristics:\n- **Addressable**: Every resource has a unique URL-based identifier\n- **Dereferenceable**: All URLs return meaningful content when accessed\n- **Versioned**: Changes are managed through the [[Weave Process|concept.weave-process]] process, and [[concept.mesh.resource.element.flow]] are versioned by default\n- **Publish-ready**: Can be served directly via GitHub Pages or similar static hosting; or via a local web server like live-server\n\n## Core Concepts\n\n### Mesh Resources\n\nThere are two primary categories:\n\n#### Mesh Nodes\n\n[[Mesh nodes|concept.mesh.resource.node]] are the primary structural components, physically represented as [[mesh folders|concept.mesh.resource-facet.folder]]. They extend namespaces and serve as containers.\n\n- **[[Namespace nodes|concept.mesh.resource.node.namespace]]**: Empty containers for organizing other mesh nodes\n- **[[Reference nodes|concept.mesh.resource.node.reference]]**: Nodes that refer to external entities (people, concepts, relationships) and contain [[reference flows|concept.mesh.resource.element.flow.reference]]\n- **[[Data nodes|concept.mesh.resource.node.data]]**: Nodes containing data distributions with optional versioning\n\n\n#### Elements\n\n[[Mesh elements|concept.mesh.resource.element]] help define, support, and systematize nodes:\n\n## Folder-based\n\n- **[[concept.mesh.resource.element.flow]]** and their [[concept.mesh.resource.element.flow.snapshot]]\n  - **[[concept.mesh.resource.element.flow.metadata]]**: System-related administrative and structural metadata for mesh nodes\n  - **[[Version datasets|concept.mesh.resource.element.flow.snapshot.version]]**: Versioned snapshots of datasets\n- **[[next snapshots|concept.mesh.resource.element.flow.snapshot.next]]**: Draft workspaces for ongoing changes to versioned datasets\n- **[[Node handles|concept.mesh.resource.element.handle]]**: Elements that provide referential indirection, allowing references to nodes as mesh resources rather than their referents\n- **[[Asset trees|concept.mesh.resource.element.asset-tree]]**: Collections of arbitrary files and folders attached to the mesh\n\n#### Files\n\nTerminal [[mesh resources|concept.mesh.resource]] that cannot contain other resources:\n\n- **[[Resource pages|concept.mesh.resource.element.documentation-resource.resource-page]]**: index.html files present in every mesh folder after weaving\n- **[[Distribution files|concept.mesh.resource.element.flow.snapshot.distribution]]**: Data files in various RDF formats\n- **README.md and CHANGELOG.md**: Documentation files providing context\n\n\n## Physical Structure\n\n### Folder Mapping\n- Mesh nodes correspond physically to [[mesh folders|concept.mesh.resource-facet.folder]]\n- Folder names become namespace segments and URL path components\n- The local [[concept.relative-identifier]] for a node matches its containing folder name\n\n### File Organization\n- [[Datasets|concept.mesh.resource-facet.dataset]] are represented by folders containing at least one distribution file\n- Distribution files must be named using the dataset's [[namespace segment|concept.namespace.segment]]\n- Resource pages (index.html) should be present in every mesh folder after [[weaving|concept.weave-process]]\n\n### Reserved Names\n- All reserved folder names begin with an underscore (_)\n- Examples: `_assets/`, `_meta-component/`, `_ref-component/`, `_current`, `_next`\n\n## Logical Structure\n\n### Namespace Extension\n- Mesh folders always extend the namespace with a segment corresponding to the folder name\n- This creates a hierarchical URL structure for addressing resources\n- Each resource has a unique [[Relative Identifier|concept.relative-identifier]] based on its path and local name\n\n### Containment Rules\n- **Mesh nodes** are always containers of elements (i.e., at least [[concept.mesh.resource.element.flow.metadata]] and [[concept.mesh.resource.folder._handle]]) and potentially containers of other nodes \n  - **namespace nodes**: no additional containment requirements\n  - **reference nodes**: must have [[concept.mesh.resource.element.flow.reference]]\n  - **data nodes**: must have [[concept.mesh.resource.element.flow.data]] with at least one distributions; and optionally, [[concept.mesh.resource.node.reference]]\n- **Assets tree elements**: Cannot contain nodes\n- all elements can contain \n\n## Rules & Constraints\n\n### System vs User Boundaries\n- **System elements**: Generated and managed by the weave process, not intended for user modification\n- **User elements**: Directly modifiable by users ([[concept.mesh.resource.element.flow.snapshot.current]], README.md, CHANGELOG.md)\n- The weave process maintains system elements and generates missing required components\n\n### Versioning Requirements\n- flow versioning is managed through the [[Versioning|concept.versioning]] system\n  - turning versioning on and off is controlled in the [[concept.mesh.resource.element.node-config-defaults]]\n  - Version history is realized in [[concept.mesh.resource.element.flow.snapshot.version]] with numbered version snapshots\n  - Version history metadata is kept in the node's [[concept.mesh.resource.element.flow.metadata]]\n\n### Addressing Requirements\n- Every mesh resource must be addressable via its URL path\n- URLs must return meaningful content when dereferenced\n  - [[concept.mesh.resource.element.documentation-resource.resource-page]] provide human-readable information for [[concept.mesh.resource-facet.folder]]-based resources\n    - resource pages are always index.html files generated by \"on weave\" from the [[concept.mesh.resource.element.documentation-resource.changelog]] and [[concept.mesh.resource.element.documentation-resource.readme]] [[concept.mesh.resource.element.documentation-resource]], templates in [[concept.mesh.resource.element.asset-tree]] and any scoped template mappings specified in [[concept.mesh.resource.element.node-config-defaults]] files \n  - [[concept.mesh.resource-facet.file]]\n\n## Integration Points\n\n### Weave Process\nThe [[Weave Process|concept.weave-process]] process maintains mesh integrity by:\n- Checking for required system resources and creating them if missing\n- Generating resource pages for changed components\n- Managing dataset versioning and metadata\n- Ensuring all resources remain addressable and dereferenceable\n\n### Publishing Workflow\n- Meshes are designed to be served directly as static sites\n- GitHub Pages integration allows immediate publishing after repository updates\n- No static site generator required, though resource page generation occurs during weaving\n- The repository structure directly maps to the published URL structure\n\n### Dataset Integration\nMeshes support multiple RDF formats and follow [[DCAT v3|related-topics.dcat.vocabulary]] standards for dataset organization. [[Datasets|concept.mesh.resource-facet.dataset]] within meshes include both standalone datasets and those embedded as mesh elements.\n","n":0.038}}},{"i":58,"$":{"0":{"v":"Flow Facet","n":0.707}}},{"i":59,"$":{"0":{"v":"versioned component","n":0.707},"1":{"v":"\nA [[concept.mesh.resource.element.flow]] whose versions are being kept around. \n\nPhysically, the historical versions are located in \"_vN\" folders, e.g. \"_v1\" or \"_v9999\". \n","n":0.213}}},{"i":60,"$":{"0":{"v":"v-series component facet","n":0.577},"1":{"v":"\nComponents with the **v-series component facet** have at least one historical checkpoint, i.e. at some point a [[concept.weave-process]] has generated a [[concept.mesh.resource.element.flow.snapshot.version]].\n\n\nA [[concept.mesh.flow-facet.versioned]] collects [[Version|concept.mesh.resource.element.flow.snapshot.version]], so a v-series components must've had versioning turned on for at least one weave.\n","n":0.16}}},{"i":61,"$":{"0":{"v":"unversioned component facet","n":0.577},"1":{"v":"\nAn unversioned node flow has never had [[concept.versioning]] turned on for a [[concept.weave-process]], so it doesn't have any [[concept.mesh.resource.element.flow.snapshot.version]]\n\nIt's useful for datasets that shouldn't change much.","n":0.196}}},{"i":62,"$":{"0":{"v":"de-versioned component","n":0.707},"1":{"v":"\nDe-versioned node flows are [[concept.mesh.resource.element.flow]] that were once versioned, but have had their versioning turned off. So there are probably [[concept.mesh.flow-facet.v-series]].\n","n":0.218}}},{"i":63,"$":{"0":{"v":"mesh resource","n":0.707},"1":{"v":"\n## Overview\n\nA **mesh resource** is any addressable component within a [[semantic mesh|concept.mesh]]. Every mesh resource has a unique [[Relative Identifier|concept.relative-identifier]] based on its path and locally unique name, making it dereferenceable via URL.\n\nIn RDF terms, a resource is any node in an RDF graph that can be represented with an IRI (the other kinds of RDF graph nodes are literals and blank nodes). So theoretically, files and folders in [[concept.mesh.resource.element.asset-tree]] could be considered RDF resources. But they are not considered **mesh** resources\n\n## Types of Mesh Resources\n\nThe structure of a semantic mesh is built on a fundamental distinction between **extensible** and **terminal** resources:\n\n- **[[Mesh nodes|concept.mesh.resource.node]]** are extensible namespace containers:\n- **[[Mesh elements|concept.mesh.resource.element]]** are terminal mesh resources:\n  - Can be physically represented as folders or files\n    - Folder [[concept.relative-identifier]] are part of the namespace but cannot be extended beyond their own internal structure\n  - All files and folders within an element folder are considerd to be part of the parent node\n\n**Folder-based elements:**\n\n\n- **[[metadata flows|concept.mesh.resource.element.flow.metadata]]**: Administrative metadata (in `_meta-component/` folders)\n- **[[reference flows|concept.mesh.resource.element.flow.reference]]**: Referent data (in `_ref-component/` folders)\n- **[[Asset trees|concept.mesh.resource.element.asset-tree]]**: File collections (in `_assets/` folders)\n- **[[Version datasets|concept.mesh.resource.element.flow.snapshot.version]]**: Versioned snapshots\n- **[[next snapshots|concept.mesh.resource.element.flow.snapshot.next]]**: Draft workspaces\n\n**File-based elements:**\n- **Documentation files**: \n  - [[Resource pages|concept.mesh.resource.element.documentation-resource.resource-page]] are index.html files that provide de-referencability for their containing [[concept.relative-identifier]] [[concept.mesh.resource-facet.folder]]\n  - **README.md and CHANGELOG.md**: unstructured documentation\n- **[[Layer distribution files|concept.mesh.resource.element.flow.snapshot.distribution]]**: Data files in RDF formats\n\n## Physical vs Logical Structure\n\n**Physical Representation:**\n- Mesh nodes and elements are represented as folders in the filesystem\n- File resources are represented as individual files\n- Folder names become namespace segments and URL path components\n\n**Logical Function:**\n- All mesh resources are addressable via their URL path\n- URLs must return meaningful content when dereferenced\n- Resources maintain semantic relationships through containment and cross-references\n\n## Asset Tree Special Case\n\n[[Asset trees|concept.mesh.resource.element.asset-tree]] represent a special category where:\n- The asset tree itself (with its [[concept.mesh.resource.element.flow.metadata]]) is part of the mesh structure\n- The files and folders contained within asset trees are \"attached to\" but not \"contained in\" the mesh\n- Asset tree contents are addressable but are not considered semantic flow resources\n\nThis distinction maintains clean separation between semantic mesh structure and arbitrary file attachments while preserving addressability.\n","n":0.054}}},{"i":64,"$":{"0":{"v":"Folder","n":1}}},{"i":65,"$":{"0":{"v":"node folder","n":0.707}}},{"i":66,"$":{"0":{"v":"namespace folder","n":0.707}}},{"i":67,"$":{"0":{"v":"version snapshot folder","n":0.577},"1":{"v":"\n- the name of [[sflo.concept.mesh.dataset-version]] folders\n","n":0.408}}},{"i":68,"$":{"0":{"v":"reference flow folder","n":0.577},"1":{"v":"\nThe physical representation of the [[concept.mesh.resource.element.flow.reference]]\n","n":0.408}}},{"i":69,"$":{"0":{"v":"next snapshot folder","n":0.577},"1":{"v":"\nPhysical manifestation of [[concept.mesh.resource.element.flow.snapshot.next]]\n\nThese folders should only contain a single \"[[working distribution|concept.working-distribution]]\", i.e., a single syntax\n","n":0.25}}},{"i":70,"$":{"0":{"v":"meta flow folder","n":0.577},"1":{"v":"\nThe physical representation of the [[concept.mesh.resource.element.flow.metadata]]\n","n":0.408}}},{"i":71,"$":{"0":{"v":"handle folder","n":0.707},"1":{"v":"\nEvery [[concept.mesh.resource.node]] contains a **handle folder** which corresponds to its [[concept.mesh.resource.element.handle]]. It provides an identifier that refers to the \"node-as-node\" rather than its referent.\n\n","n":0.204}}},{"i":72,"$":{"0":{"v":"data flow folder","n":0.577},"1":{"v":"\nThe physical representation of a [[concept.mesh.resource.element.flow.data]] dataset\n","n":0.378}}},{"i":73,"$":{"0":{"v":"current snapshot folder","n":0.577},"1":{"v":"\n- an [[concept.mesh.resource.element.flow.snapshot]]\n","n":0.577}}},{"i":74,"$":{"0":{"v":"config flow folder","n":0.577},"1":{"v":"\nThe physical representation of the [[concept.mesh.resource.element.flow.config]]\n","n":0.408}}},{"i":75,"$":{"0":{"v":"assets tree folder","n":0.577},"1":{"v":"\n- correspond to [[concept.mesh.resource.element.asset-tree]]s \n","n":0.447}}},{"i":76,"$":{"0":{"v":"MeshNode","n":1},"1":{"v":"\n## Overview\n\nThe primary constituents of a semantic mesh are **mesh nodes**. They are physically represented as [[mesh folders|concept.mesh.resource-facet.folder]] and provide one type of [[namespace segments|concept.namespace.segment]].\n\nMesh nodes are extensible namespace containers that can contain other mesh nodes and [[mesh elements|concept.mesh.resource.element]], distinguishing them from elements which are terminal within their own scope.\n\n## Physical Structure\n\nWhen stored on disk, all mesh nodes:\n- Are physically represented as folders in the filesystem\n- Have folder names that become namespace segments\n- Extend the URL namespace with their folder name\n- Can be further extended by containing other mesh resources\n\n## Mandatory Elements\n\nEvery mesh node has these elements:\n\n- **[[concept.mesh.resource.element.flow.metadata]]** (`_meta-component/`): Centralized metadata for the node\n- **[[concept.mesh.resource.element.handle]]** (`_node-handle/`): Universal marker folder that refers to the parent \"as a mesh node\", as opposed to \"as the name, dataset, or other thing\" to which it normally refers; a handle resource page should explain this distinction\n\n## Node Types\n\n### 1. [[Namespace Node|concept.mesh.resource.node.namespace]]\n**Elements**: `_meta-component/` + `_node-handle/`\n- Functions as organizational containers\n- Contains essential identity, metadata, and handle information\n- Node IRI refers to the namespace itself\n- Base level for all mesh nodes\n\n### 2. [[Reference Node|concept.mesh.resource.node.reference]]\n**Elements**: `_meta-component/` + `_node-handle/` + `_ref-component/`\n- Represents external entities (people, concepts, relationships)\n- Node IRI refers to the external entity being referenced\n- Adds reference data capabilities to the namespace foundation\n- Evolved from namespace nodes by adding the `_ref-component/` element\n- Maintains single referent principle - the node refers to the external entity\n\n### 3. [[Data Node|concept.mesh.resource.node.data]]\n**Elements**: `_meta-component/` + `_node-handle/` + `_data-component/` ( + optional `_ref-component`)\n- Contains data distributions and versioning capabilities\n- Node IRI refers to the node flow\n- Adds dataset storage to the namespace foundation\n- Can be configured as [[dataset series|concept.mesh.resource.node.data.series]]\n- Evolved from namespace nodes by adding the `_data-component/` element\n- Maintains single referent principle - the node refers to the dataset\n","n":0.059}}},{"i":77,"$":{"0":{"v":"reference node","n":0.707},"1":{"v":"\nreference nodes are the main semantic constituents of a [[concept.mesh]]\n\nLike all [[concept.mesh.resource.node]], they have an [[concept.mesh.resource.element.handle]]\n\nThe defining feature of a **reference node** is that it has an associated [[concept.mesh.resource.element.flow.reference]]. It is a resource in the conventional RDF sense that it can be referred to in RDF data, i.e. as the subject or object of a triple.\n","n":0.134}}},{"i":78,"$":{"0":{"v":"namespace node","n":0.707},"1":{"v":"\n**Namespace nodes** are [[mesh nodes|concept.mesh.resource.node]] that function primarily as containers for other mesh nodes. They are physically represented by [[concept.mesh.resource.folder.namespace]]\n\nA secondary, optional function is as \"semantic contextualizers\", but namespace nodes don't have any clear [[related-topics.referent]] of their own. ","n":0.162}}},{"i":79,"$":{"0":{"v":"data node","n":0.707},"1":{"v":"\n## Overview\n\n**Data nodes** are [[mesh nodes|concept.mesh.resource.node]] that represent a data concept, have an abstract \"payload\" dataset in the form of an [[concept.mesh.resource.element.flow.data]] (an [[concept.mesh.resource.element.flow]]). The node data flow is in turn instantiated by conceptual [[concept.mesh.resource.element.flow.snapshot]]s that represent the data's evolution and current state.\n\nUnlike [[dataset elements|concept.mesh.resource.element.flow.snapshot]] which contain concrete data distributions, data nodes serve as conceptual containers that organize and provide identity for data without containing the data directly. I.e., Data nodes only contain concrete datasets by virtue of containing [[concept.mesh.resource.element.flow.data]] (also abstract) and its layers, which have concrete distributions.\n\nData nodes are physically represented as [[mesh folders|concept.mesh.resource-facet.folder]] and correspond to [[namespace segments|concept.namespace.segment]].\n\n## Abstract vs Concrete Data\n\n### Abstract Data Concept (Data Node)\nA data node represents the **idea** or **concept** represented by a dataset:\n- `/ns/djradon/bio/` = a biographical dataset about the person djradon\n- `/ns/census/` =  the results of a census\n- `/ns/weather-stations/` = \"the concept of weather station data\"\nThis idea or concept is the referent of the data node's URL. \n\nThe data node provides:\n- **Stable identity**: The concept persists even as concrete data changes\n- **Organizational structure**\n\n### data flows (Dataset Elements)\n\n[[concept.mesh.resource.element.flow.data]] refer to themselves and contain layers:\n\n- `/ns/monsters/_data/_v4/` = \"the current monster data flow\"\n- `/ns/weather-stations/_v3/` = \"version 3 of weather station data\"\n\nThese elements contain:\n- **Distribution files**: The actual data in various formats\n- **Concrete metadata**: Information about this specific data instance\n\n## Required Structure\n\nEvery data node must contain:\n\n- **[[concept.mesh.resource.element.flow.metadata]]** (`_meta-component/`): Administrative metadata about the data concept\n- **[[concept.mesh.resource.element.flow.data]]** (`_data-component/`): dataset data\n- **[[Node handle|concept.mesh.resource.element.handle]]** (`_node-handle/`): Referential indirection for the node\n\n\n## Optional Structure\n\n- **[[Asset trees|concept.mesh.resource.element.asset-tree]]** (`_assets/`): Attached file collections\n- [[concept.mesh.resource.element.documentation-resource.changelog]] and [[concept.mesh.resource.element.documentation-resource.readme]]\n- [[concept.mesh.resource.element.node-config-defaults]]\n- [[concept.mesh.resource.element.flow.unified]] \n\n## Key Characteristics\n\n### Not a Dataset\n\n**Important**: A data node does not refer to a specifc RDF graph; it is **not itself a (concrete) dataset**. It represents the abstract concept of a dataset that may evolve over time:\n- Data nodes are never versioned (only their elements are)\n- Data nodes serve as stable conceptual anchors\n\n### Overlap with Reference Nodes\n\nData nodes function like [[reference nodes|concept.mesh.resource.node.reference]], in that they refer to something... but their referent is very specific: an (abstract) dataset that may evolve over time.\n\n### Extensible Container\nLike all mesh nodes, data nodes can contain other mesh nodes and elements, making them extensible namespace containers.\n\n## Examples\n\n### Unversioned Data Node\n```\nns/monsters/\n├── _meta-component/        # metadata about an abstract \"monsters dataset\"\n├── _node-handle/           # handle for the data node\n└── _current/               # current monster data\n    ├── monsters.jsonld     # concrete distribution of the current monster snapshot\n    └── monsters.ttl\n```\n\n","n":0.051}}},{"i":80,"$":{"0":{"v":"mesh data-series node","n":0.577},"1":{"v":"\n\n\nA **mesh dataset-series node** is not generally distinguished from **[[concept.mesh.resource.node.data]]s** in terms of file structure, but their metadata should identify them as [[related-topics.dcat.dataset-series]] and identify the datasets in their series.\n\nThe contained datasets don't need to physically live inside the series' folder, but that can be an intuitive design pattern.\n\n[[concept.mesh.flow-facet.versioned]] are not mesh dataset-series themselves, but they contain [[concept.mesh.flow-facet.v-series]] which are. (And [[concept.mesh.resource.element.flow.snapshot.version]] that are not.) ","n":0.124}}},{"i":81,"$":{"0":{"v":"mesh element","n":0.707},"1":{"v":"\n## Overview\n\n**Mesh elements** are terminal mesh resources that support and define the mesh structure. Unlike [[mesh nodes|concept.mesh.resource.node]] which can contain other mesh resources, elements cannot be extended beyond their own internal structure.\n\nElements can be physically represented as folders or files, and all files and folders within an element folder are considered to be part of that element.\n\n## Element Categories\n\nElements are categorized by their facets, including:\n  - typical creation and maintenance patterns (user vs system)\n  - verioning status\n  - folder vs. file\n  - node role (name, reference, and data [[concept.mesh.resource.element.flow]])\n\n### User Elements\n\nUser elements are primarily created and maintained by users or their software agents and services, and represent domain knowledge:\n\n**Folder-based user elements:**\n- **[[Asset trees|concept.mesh.resource.element.asset-tree]]**: Collections of arbitrary files attached to the mesh (in `_assets/` folders)\n- **[[Next datasets|concept.mesh.resource.element.flow.snapshot.next]]**: Draft workspaces for ongoing changes to [[concept.mesh.resource.element.flow]] (in `_next/` folders)\n\n**File-based user elements:**\n- **README.md files**: User documentation providing context\n- **CHANGELOG.md files**: Version history documentation\n\n### System Elements\n\nSystem elements are usually created or altered by the [[Weave Process|concept.weave-process]] process rather than direct user modification:\n\n**Folder-based system elements:**\n- **[[metadata flows|concept.mesh.resource.element.flow.metadata]]**: Administrative and structural metadata for mesh nodes (in `_meta-component/` folders)\n- **[[version snapshot|concept.mesh.resource.element.flow.snapshot.version]]**: Versioned snapshots of datasets (in `_vN/` folders)\n- **[[Node handles|concept.mesh.resource.element.handle]]**: Elements providing referential indirection for nodes as mesh resources (in `_node-handle/` folders)\n- [[concept.mesh.resource.element.flow.unified]]\n\n**File-based system elements:**\n- **[[Resource pages|concept.mesh.resource.element.documentation-resource.resource-page]]**: Generated index.html files for human-readable access\n- **[[Distribution files|concept.mesh.resource.element.flow.snapshot.distribution]]**: Data files in various RDF formats\n\n## Physical vs Logical Structure\n\n**Physical Representation:**\n- Folder-based elements are represented as folders with underscore prefixes (like `_meta-component/`, `_ref-component/`, `_assets/`)\n- File-based elements are individual files within mesh nodes or other elements\n- Element folders contain all files and folders that belong to that element\n\n**Logical Function:**\n- Elements extend the namespace but are terminal (cannot contain other mesh nodes or elements)\n- Elements provide specialized functionality: metadata, versioning, referential data, or file attachments\n- Elements maintain the semantic structure and operational capabilities of the mesh\n\n## Integration with Nodes\n\nElements work in conjunction with mesh nodes to create the complete mesh structure:\n- Every mesh node contains at least two elements: metadata flows and node handles\n- Reference nodes contain reference flows \n- data nodes may also contain reference flows, but their defining component is the [[concept.mesh.resource.element.flow.data]]\n- Any node may contain asset trees (user elements) for file attachments\n","n":0.053}}},{"i":82,"$":{"0":{"v":"Node Config Defaults","n":0.577},"1":{"v":"\n- flow versioning on | off\n- fragment generation \n- distribution syntaxes\n- unified flow on | off\n- aggregate dataset \n- copyright / licensing / attribution / delegation chaing defaults","n":0.189}}},{"i":83,"$":{"0":{"v":"handle","n":1},"1":{"v":"\nA **handle** is a simple element that supports [[concept.mesh.resource.node]]s. It has a very special semantic use: instead of refering to itself, it refers to its containing node \"as a mesh resource.\" So it becomes a \"management interface\" for the node.\n\n## Example\n\nIf `/temperature-data/` URL refers to an abstract dataset, `/temperature-data/_handle` refers to the temperature-data node itself: something that can have a node config and provenance metadata about who created the node (as opposed to who created the dataset).\n\n## Justification\n\nElement identifiers don't have an obvious referent other than themselves. e.g., ns/djradon/bio-dataset/_data refers only to a specific [[concept.mesh.resource.element.flow]]. \n\nSo when they're mentioned in [[concept.mesh.resource.element.flow.metadata]] or [[concept.mesh.resource.element.flow.config]], it's clear enough that their identifiers refer to them \"as mesh resources.\"\n\nBut because the URL of a [[concept.mesh.resource.node]] refers to a namespace; an abstract dataset; or a thing or concept --  based on the [[principle.single-referent]] principle, you should not use the node's URL to refer to it \"as a mesh resource.\"\n\n## Issues\n\n### No URL to refer to the handle itself\n\nLuckily there's not much reason to have to refer to the handle-as-mesh-element because they are always co-created with the node, live forever, never change, don't have data of their own. But you can use the \"fragment identifier\" trick if there's ever a need to refer to the handle. e.g. /temperature-data/_handle/#\n\n\n## Containment Rules\n\n- must-be-contained-in: [[concept.mesh.resource.node]]\n- cannot-be-contained-in: \n  - [[concept.mesh.resource.element]]\n","n":0.067}}},{"i":84,"$":{"0":{"v":"handle resource page","n":0.577},"1":{"v":"\n- provides an accessible description of its containing [[concept.mesh.resource.element.handle]]. \n- be default it could be something simple like \"For Semantic Web purposes, this URL should be considered to connote the Semantic Mesh Node <ns/djradon>, not djradon the thing.\"","n":0.162}}},{"i":85,"$":{"0":{"v":"node flow","n":0.707},"1":{"v":"\nThere are three types of node flows - they are the most important parts of a node:\n\n    - [[sflo.concept.mesh.resource.element.node-component.metadata]] (mandatory)\n    - [[sflo.concept.mesh.resource.element.node-component.reference]] (optional)\n    - [[sflo.concept.mesh.resource.element.node-component.data]] (only for [[sflo.concept.mesh.resource.node.data]])\n\n**node flows** are dcat:DatasetSeries representing abstract datasets about their node's metadata, referent, and payload data that exist through time, independent of any specific version or realization.\n\n## Relationship to node flows\n\nAs DatasetSeries, node flows are realized through [[concept.mesh.resource.element.flow.snapshot]], which are temporal concrete versions of the abstract concept. To borrow a phrase from the PROV model, we say that a layer is a specialization of the node flow.\n\n### Relationship pattern:\n\nEvery node flow has at least two concrete layers: [[concept.mesh.resource.element.flow.snapshot.current]] and [[concept.mesh.resource.element.flow.snapshot.next]].\n\nThe node flow is a [[related-topics.dcat.dataset-series]] and may have multiple flow snapshots, i.e., [[concept.mesh.resource.element.flow.snapshot.version]]s.\n\n- node flow: \"My ontology definitions\" (persistent concept)\n- flow snapshots: v1.0, v1.1, current version, working draft of next version (specific realizations)\n\n### Ontology Example\n\n```file\n/my-ontology/\n├── _ref-component/                    ← node flow (reference data about ontology)\n│   ├── _current/           ← flow snapshot\n│   ├── _v1/                ← flow snapshot  \n│   └── _v2/                ← flow snapshot\n└── _data-component/                  ← node flow (ontology definitions)\n    ├── _current/           ← flow snapshot\n    └── _v1/                ← flow snapshot\n```\n\nIn this example:\n\n_ref/ represents the node flow of reference information about the ontology\n_data/ represents the node flow of the ontology's definitional content\nEach _current/, _v1/, etc. contains flow snapshot realizations\n\n## Persistent Identity\n\nnode flows provide conceptual continuity by:\n\n- Maintaining meaning across versions and changes\n- Preserving references from external sources\n- Enabling evolution while keeping identity stable\n- Supporting versioning without losing conceptual coherence\n","n":0.065}}},{"i":86,"$":{"0":{"v":"unified dataset","n":0.707},"1":{"v":"\n## Overview\n\nA **unified dataset** provides convenient aggregated access to a mesh node's current state by combining data from its non-config [[flows|concept.mesh.resource.element.flow]] (meta, ref, data) into a single [[concept.mesh.resource.element.flow.snapshot]] with corresponding distribution files.\n\nSince it is fundamentally a combination, it only makes sense to generate a unified component for nodes that have more than one component, i.e., not [[concept.mesh.resource.node.namespace]].\n\n## Component or Not?\n\nLike all components:\n\n- its associated with a [[concept.mesh.resource.node]]\n- its a DatasetSeries that consists of \"state layers\" that have distributions\n- its metadata is kept in its sibling [[concept.mesh.resource.element.flow.metadata]]\n- it has independent versioning, and a _current snapshot which duplicates the latest version\n\nLike the metadata flow: \n\n- it is generated by the [[system|concept.mesh.resource-facet.system]] and so is not considered [[user-modifiable|concept.mesh.resource-facet.user]]\n- no _next snapshot (or _next is just temporary during weave)\n- System components always version together in response to user component changes.\n\nUnlike other components:\n\n- it doesn't contain any data of its own; it's more a view than a source\n\n\n## Architecture\n\n### IRI Structure & Single Referent Compliance\n- **Node IRI** (`ns/djradon/bio-dataset/`) refers to its semantic entity (abstract dataset or thing)\n- **Unified Component IRI** (`ns/djradon/bio-dataset/_unified/`) refers to the aggregated DatasetSeries\n- **Distribution files** are serializations of the unified dataset\n- **No violation** of [[single referent principle|principle.single-referent]]\n\n### Content Composition\n```turtle\n# Example unified dataset content\n@prefix flow: <https://semantic-flow.github.io/sflo-ontology/> .\n\n# Unified dataset describes its aggregation\n<ns/djradon/bio-dataset/_unified/> a dcat:Dataset ;\n  dct:title \"Unified view of bio-dataset node\" ;\n  flow:aggregatedFrom [\n    flow:metaDataset <ns/djradon/bio-dataset/_meta-component/v2/> ;\n    flow:dataDataset <ns/djradon/bio-dataset/_data-component/v1/> ;\n    flow:aggregatedAt \"2025-01-03T19:06:34Z\"^^xsd:dateTime\n  ] .\n\n<ns/djradon/bio-dataset/_meta/_current/> {\n  # Current meta dataset content\n}\n\n<ns/djradon/bio-dataset/_data/_current/> {\n  # Current data dataset content\n}\n```\n\n## Benefits\n\n### Developer Experience\n- **Single file access**: Complete node state in one distribution\n- **Atomic consistency**: Guaranteed consistent snapshot of all components\n- **Simplified client code**: No need to understand internal node structure\n\n### Performance\n- **Reduced HTTP requests**: One file instead of 3+ component requests\n- **Bandwidth efficiency**: Optimized for common \"give me everything about this node\" use case\n\n### Provenance \n- **Version tracking**: Metadata about which flow versions were aggregated\n- **Audit trail**: Clear record of what was combined and when\n- **Debugging**: Easy to see complete node state at specific point in time\n\n## Implementation Considerations\n\n### Generation Strategy\n- **Event-driven**: Regenerate on any version-bumping weave\n\n### Synchronization\n- **Consistency checks**: Validate component datasets before aggregation\n- **Error handling**: Graceful degradation when components missing/invalid\n- **Race conditions**: Handle concurrent updates to components\n\n### Storage\n- **Disk space**: Additional storage overhead for duplicated data\n\n## Technical Requirements\n\n### File Naming\n- Pattern: `{node-name}_unified.{format}` (e.g., `bio-dataset_unified.trig`)\n- Consistent across all node types\n- Clear differentiation from component dataset files\n\n### Content Validation\n- **Component availability**: All required components must exist\n- **RDF validity**: Generated content must be valid RDF\n- **Graph organization**: Clear separation of component data via named graphs\n\n\n**Why not always use a unified dataset?**\n\n- **Node type detection**: Folder existence (`_ref/` vs `_data/`) indicates node type without parsing\n- **Granular access**: Clients can request specific components (meta-only, data-only)\n- **Independent versioning**: Components can evolve at different rates\n- **Clear semantics**: Each dataset has focused, well-defined purpose\n\n**Why bother with a unified dataset?**\n\n**Unified approach benefits**:\n- **Simplicity**: Single dataset per node reduces complexity\n- **Atomic consistency**: All components always synchronized\n\n## Related Concepts\n\n- [[concept.mesh.resource.node]] - Base mesh node architecture\n- [[concept.mesh.resource.element.flow.metadata]] - Centralized metadata\n- [[concept.mesh.resource.element.flow.snapshot.distribution]] - Distribution file concepts\n","n":0.045}}},{"i":87,"$":{"0":{"v":"flow snapshot","n":0.707},"1":{"v":"\n**flow snapshots** are mesh elements that are datasets and represent the evolutionary steps of [[concept.mesh.resource.element.flow]], whether [[concept.mesh.resource.element.flow.metadata]], [[concept.mesh.resource.element.flow.reference]], or [[concept.mesh.resource.element.flow.data]]. \n\nflow snapshots have corresponding [[distributions|concept.mesh.resource.element.flow.snapshot.distribution]] and are the connective tissue between nodes and their RDF-based representation.\n\n## Relationship to node flows\n\nflow snapshots are the successive realizations of [[concept.mesh.resource.element.flow]].\n\n### Relationship pattern:\n\nnode flows have at least two layers:\n\n- current version (`_current/`)\n- working version (`_next`)\n\nVersioned components \n\n### Ontology Data Node Example\n\n```file\n/my-ontology/               ← Data Node: Conceptual, data-oriented \"thing\"\n├── _meta-component/                   ← Reference node flow (reference data about ontology)\n│   ├── _current/           ← flow snapshot (current reference data)\n│   ├── _next/              ← flow snapshot (working draft)\n│   ├── _v1/                ← flow snapshot (version 1 reference data)\n│   └── _v2/                ← flow snapshot (version 2 reference data)\n├── _ref-component/                   ← Reference node flow (reference data about ontology)\n│   ├── _current/           ← flow snapshot (current reference data)\n│   ├── _next/              ← flow snapshot (working draft)\n│   ├── _v1/                ← flow snapshot (version 1 reference data)\n│   └── _v2/                ← flow snapshot (version 2 reference data)\n└── _data-component/                  ← Data node flow (ontology definition--by-dataset)\n    ├── _current/           ← flow snapshot (current definition)\n    ├── _next/              ← flow snapshot (working draft)\n    └── _v1/                ← flow snapshot (version 1 definition)\n```\n\nIn this example:\n- `_current/`, `_v1/`, `_v2/`, `_next/` are all flow snapshots\n- Each contains actual data files and distributions\n- They represent specific temporal states of their parent node flows\n\n## Temporal Nature\n\nflow snapshots capture datasets at specific moments:\n\n- **Current versions** (`_current/`) - The active working state\n- **Next versions** (`_next/`) - Draft content for future release\n- **Historical versions** (`_v1/`, `_v2/`) - Immutable snapshots from the past\n\n## Content Structure\n\nflow snapshots contain:\n- **Data files** - The actual dataset content (`.ttl`, `.rdf`, `.jsonld`)\n- **Distributions** - Multiple format representations of the same data\n- **Metadata** - Information about the specific version/snapshot\n\n### Example Structure\n```file\n_current/\n├── my-ontology.ttl         ← Distribution\n├── my-ontology.rdf         ← Distribution  \n└── my-ontology.jsonld      ← Distribution\n```\n\n## Immutability\n\n**[[concept.mesh.resource.element.flow.snapshot.version]]** (historical flow snapshots, i.e., versioned folders like `_v1/`, `_v2/`) should be treated as immutable once created. This provides reliable references for external systems and ensures accurate provenance and history.\n\n**[[concept.mesh.resource.element.flow.snapshot.current]]** (the latest \"woven\" flow snapshots, `_current`) should not be modified directly by users, but will be updated \"on weave\" if the [[concept.mesh.resource.element.flow.snapshot.next]] has evolved. \n\n**[[concept.mesh.resource.element.flow.snapshot.next]]** (working flow snapshots, `_next/`) are mutable:\n- Can be edited and updated during development\n- Represent evolving state of the node flow\n\n## Creation and Lifecycle\n\nflow snapshots are created through:\n- **Initial authoring** - Creating `_current/` content\n- **Versioning** - Snapshotting `_current/` to `_v1/`, `_v2/` during [[sflo.concept.weave]]\n- **Draft preparation** - Working in `_next/` for future releases\n\n## Related Concepts\n\n- **[[concept.mesh.resource.element.flow]]** - Parent conceptual entities\n- **[[concept.versioning]]** - Process of creating versioned flow snapshots\n- **[[concept.weave-process]]** - Operation that manages flow snapshot lifecycle\n","n":0.049}}},{"i":88,"$":{"0":{"v":"version snapshot","n":0.707},"1":{"v":"\nA snapshot or checkpoint dataset generated \"on [[weave|concept.weave-process]]\" for [[concept.mesh.flow-facet.versioned]]\n\n## Containment Rules\n\n- can-be-contained-in: [[concept.mesh.flow-facet.v-series]]\n- cannot-be-contained-in: anything else\n\n## Disambiguation\n\n- a version snapshot  is an addressable resource; it is differentiated from the concept of a [[concept.mesh.flow-facet.versioned]]\n","n":0.171}}},{"i":89,"$":{"0":{"v":"next snapshot","n":0.707},"1":{"v":"\nThe **next snapshot** serves as a draft workspace for ongoing changes to a node's  ([[concept.mesh.resource.element.flow]])\n\nAfter a version-bumping weave, a next snapshot starts identically to the current dataset but can be modified safely without affecting the stable current version. During weaving, _next content becomes the new current dataset and gets snapshotted as the latest version, while _next naturally remains ready for the next round of drafts.\n\nThis allows continuous development and version control commits without requiring immediate version bumps or disrupting users of the stable dataset.\n\n\n## Containment Rules\n\n- must-be-contained-in: [[concept.mesh.resource.element.flow.reference]], [[concept.mesh.resource.element.flow.data]], or both\n","n":0.105}}},{"i":90,"$":{"0":{"v":"layer distribution","n":0.707},"1":{"v":"\n- [[concept.mesh.resource.element.flow.snapshot]] should have one or more distributions.\n- a layer's distributions should contain the same data, just in different syntaxes \n\n## Naming\n\n- [[concept.mesh.resource.element.flow.metadata]] and [[concept.mesh.resource.element.flow.reference]] have their distributions named with \"_meta\" and \"_ref\" respectively, but\n- [[concept.mesh.resource.element.flow.data]], being the \"payload data\", \n\n\n## Issues\n\n- TODO: should we only support \"named graph\"-support formats\n\n## RDF file extensions Support\n\n| Serialization | supported?  | Media Type              | Typical File Extension(s) | Notes                                         |\n| ------------- | ----------- | ----------------------- | ------------------------- |\n| **JSON-LD**   | in progress | `application/ld+json`   | `.jsonld`, `.json`        | JSON-based Linked Data.                       |\n| **Turtle**    | in progress | `text/turtle`           | `.ttl`                    | Widely used, human-readable.                  |\n| **TriG**      | n           | `application/trig`      | `.trig`                   | Turtle + named graphs.                        |\n| **RDF/XML**   | n           | `application/rdf+xml`   | `.rdf`, `.xml`            | The original W3C syntax, verbose XML.         |\n| **Notation3** | n           | `text/n3` (informal)    | `.n3`                     | Superset of Turtle with logical implications. |\n| **N-Triples** | n           | `application/n-triples` | `.nt`                     | Line-based, one triple per line.              |\n| **N-Quads**   | n           | `application/n-quads`   | `.nq`, `.quad`            | Like N-Triples but with graph label.          |\n| **HDT**       | n           | (binary)                | `.hdt`                    | Compressed, random-access format.             |\n","n":0.073}}},{"i":91,"$":{"0":{"v":"current snapshot","n":0.707},"1":{"v":"\nThe current snapshot represents the stable, published version of a dataset's content. It serves as the authoritative source that users and external systems reference, containing the most recent released data while remaining unchanged during active development.\n\nThe current snapshot always matches the content of the latest versioned layer (e.g., `_v3/`) and remains identical to the [[concept.mesh.resource.element.flow.snapshot.next]] until new changes begin. During weaving, the `_next` content becomes the new current snapshot and gets snapshotted as the next version, ensuring the current snapshot stays synchronized with the latest stable release.\n\nThis provides a stable reference point for citations and external links while allowing ongoing development work to proceed safely in the `_next` dataset without disrupting users of the published data.\n","n":0.093}}},{"i":92,"$":{"0":{"v":"reference flow","n":0.707},"1":{"v":"\n- one of the [[semantic flow elements|concept.mesh.resource.element]]\n- used for attaching data to a [[concept.mesh.resource.node.reference]]\n- logically, it's a [[concept.mesh.flow-facet.versioned]], so contains a [[concept.mesh.flow-facet.v-series]]\n- physically represented as a [[concept.mesh.resource.folder._ref-flow]]\n- not a [[concept.mesh.resource.node]], so doesn't have its own [[concept.mesh.resource.element.flow.metadata]]\n  - metadata is kept in its parent node's metadata flow\n","n":0.147}}},{"i":93,"$":{"0":{"v":"metadata flow","n":0.707},"1":{"v":"\nA **metadata flow** contains system-related administrative and structural metadata for every [[concept.mesh.resource.node]], including the versioning data for each node's flows.\n\nPhysically, it exists as a [[concept.mesh.resource.folder._meta-flow]] in a [[concept.mesh.resource.folder.node]].\n\nMesh-specific metadata about a node's [[concept.mesh.resource.element.flow.snapshot.version]] mostly lives here too, eliminating the need to keep separate metadata in the element. \n\n## Use of _handle in metadata flows\n\nWhen metadata flows (or any [[concept.mesh.resource-facet.system]] dataset) refer to mesh nodes, they'll usually be talking about \"the-node-as-mesh-constituent\", so they'll use the node's [[concept.mesh.resource.element.handle]] identifier\n\n## Recommended vocabulary\n\n","n":0.113}}},{"i":94,"$":{"0":{"v":"data flow","n":0.707},"1":{"v":"\n## Overview\n\ndata flows (_data-component/) are [[node flows|concept.mesh.resource.element.flow]] that effectively associate a versioned dataset with a mesh node. They contain the actual content payload of data nodes and provide the primary data storage functionality within the semantic flow mesh architecture.\n\n## Purpose\n\ndata flows serve as the primary content containers for mesh nodes, providing:\n\n- **Content Storage**: Hold the actual data payload that defines the node's content\n- **Version Management**: Support multiple versions of the same conceptual dataset\n- **Format Diversity**: Enable multiple data format distributions (TTL, JSON-LD, etc.)\n- **State Management**: Track current, draft, and versioned states of data\n\n## Structure\n\ndata flows organize content through [[flow snapshots|concept.mesh.resource.element.flow.snapshot]]:\n\n- `_current/` - Current stable version of the dataset\n- `_next/` - Draft/work-in-progress version\n- `_v1/`, `_v2/`, etc. - Versioned snapshots for historical access\n\nLike all [[concept.mesh.resource-facet.folder]], they should contain an `index.html` [[concept.mesh.resource.element.documentation-resource.resource-page]] -- a human-readable description for the component\n\n\n## Relationship to Data Nodes\n\ndata flows create the fundamental association between nodes and their content:\n\n\n## Content Types\n\ndata flows contain one or more \n\n## Versioning Strategy\n\ndata flows implement sophisticated version management:\n\n- **Linear Versioning**: Sequential versions (v1, v2, v3...)\n- **Branch Management**: Current stable vs. next draft\n- **Snapshot Preservation**: Historical versions remain accessible\n- **Aggregated Access**: Top-level files provide consolidated views\n\n## Distribution Formats\n\nEach flow snapshot typically provides multiple format distributions:\n\n- **Trig (.trig)**: Primary RDF serialization\n- **JSON-LD (.jsonld)**: JSON-compatible linked data\n- **RDF/XML (.xml or .trix)**: XML-based RDF serialization\n- **N-Quads (.nq)**: Line-based RDF format\n\n## Example\n\nFrom the [[semantic mesh example|concept.semantic-mesh.example]]:\n\n```\n/test-ns/djradon-bio/_data/          # data flow\n├── _current/                        # current snapshot\n│   ├── djradon-bio.ttl             # turtle distribution\n│   ├── djradon-bio.jsonld          # json-ld distribution\n│   └── index.html                  # layer interface\n├── _next/                          # draft layer\n│   ├── djradon-bio.ttl             # draft turtle\n│   ├── djradon-bio.jsonld          # draft json-ld\n│   └── index.html                  # layer interface\n└── index.html                      # component interface\n```\n\n## Integration\n\ndata flows integrate with other mesh elements:\n\n- **metadata flows**: Provide provenance and management data\n- **reference flows**: Enable indirection and linking\n- **Asset Trees**: Store associated files and media\n- **Resource Pages**: Provide human-readable interfaces\n\ndata flows are the core content mechanism that enables the semantic flow mesh to function as a distributed, versioned knowledge management system.\n","n":0.055}}},{"i":95,"$":{"0":{"v":"config component","n":0.707},"1":{"v":"\n\nNode configuration can be inherited from any parent nodes, and overrides are accomplished with an optional node `_config-component` that travels with the node and is distinct from the `_meta-component`.\n\nDefault configuration can be determined recursing up  [[concept.mesh.resource.element.node-config-defaults]], which can also be inherited from parent nodes. \n\nInheritance of configuration and defaults can be turned off. \n\nIn case of missing configuration and absence of user defaults, the system will use sensible defaults which can be specified in the [[concept.node-config]]\n\n## Core Principles\n\n### Node-Config as node flow\n- **Optional**: \n- **Transposable**: Node config travels with nodes during import/graft operations\n- **Composable**: Each node may have its own self-contained configuration, but i\n\n### Defaults vs Config\n- **Config**: Actual operational settings for a specific node\n- **Defaults**: Fallback values when config is missing or incomplete\n- **Defaults inheritance**: Only occurs when needed, walks up mesh hierarchy\n- **Most specific wins**: Closer defaults override higher-level ones\n\n## Component Structure\n\n### Separate Components\n- `_config-component`: Operational behavior settings\n- `_meta-component`: Structural/system metadata\n- **Rationale**: Different update cadences, concerns, and responsibilities\n\n### File Structure\n```\n/node-path/\n  _config-component/\n    _current/\n      config.jsonld\n    _next/           # optional, for pending changes\n      config.jsonld\n```\n\n## Config Resolution Logic\n\n### When Config is Retrieved\n1. **Has valid config**: Use node's `_config-component` directly\n2. **No config exists**: Walk up tree for defaults, create new config\n3. **Missing required fields**: Fill gaps from defaults hierarchy\n\n### Defaults Resolution\n- Walk up mesh hierarchy from node to root\n- Collect defaults at each level that has `flow-config-defaults`\n- Most specific (closest to node) takes precedence\n- Create complete config from merged defaults\n\n## Schema Management\n\n### Schema Versioning\n- Each config includes `schemaVersion` field\n- Schema updates trigger config validation\n- Backward compatibility maintained where possible\n\n### Update Operations\n- `flow update` command handles schema migrations\n- Can target specific subtrees or entire mesh\n- Triggers defaults walk for outdated/missing configs\n\n## Import/Export Behavior\n\n### Import Decisions\n- **Interactive mode**: User chooses keep/replace/merge\n- **Automated mode**: Policy-driven decisions\n- **Per-node basis**: Each node's config handled independently\n- **No merging required**: One config per node eliminates conflicts\n\n### Transposability\n- Config components travel with nodes during operations\n- Option to reset config during import (use target mesh defaults)\n- Maintains semantic consistency across mesh boundaries\n\n## Implementation Considerations\n\n### Config Manager Interface\n```typescript\ninterface ConfigManager {\n  loadNodeConfig(nodePath: string): NodeConfig | null\n  resolveConfig(nodePath: string): NodeConfig\n  createFromDefaults(nodePath: string): NodeConfig\n  updateConfigSchema(nodePath: string, newSchema: string): void\n  validateConfig(config: NodeConfig): ValidationResult\n}\n```\n\n### Service vs Node Config\n- **Service config**: API endpoints, auth, global policies\n- **Node config**: Weave behavior, validation rules, local settings\n- **Clear separation**: Different storage, lifecycle, and scope\n\n## Key Benefits\n\n### Predictability\n- No complex inheritance chains\n- Clear resolution rules\n- System-guaranteed validity\n\n### Flexibility\n- Granular per-node control\n- Interactive import decisions\n- Targeted update operations\n\n### Maintainability\n- Separate concerns (config vs metadata)\n- Schema evolution support\n- Backward compatibility\n\n## Operational Workflows\n\n### New Node Creation\n1. System generates default config from hierarchy\n2. Creates `_config-component` with resolved settings\n3. Config immediately available and valid\n\n### Config Updates\n1. Modify `_next` layer in `_config-component`\n2. Validate against current schema\n3. Weave operation promotes to `_current`\n\n### Schema Migration\n1. `flow update` identifies outdated configs\n2. Walks defaults for missing/new required fields\n3. Updates `schemaVersion` and validates\n4. Preserves existing valid settings\n","n":0.046}}},{"i":96,"$":{"0":{"v":"Config Inheritance Resolution","n":0.577},"1":{"v":"\n# InheritableNodeConfig Inheritance Resolution\n\n## Overview\n\nThe Semantic Flow platform supports sophisticated configuration inheritance through the `InheritableNodeConfig` class. This document describes how inheritance resolution works across the platform, service, and node hierarchy.\n\n## Core Concepts\n\n### Two Types of Configuration\n\n1. **OperationalNodeConfig**: A node's actual operational settings that control its behavior\n   - Does NOT participate in inheritance chain\n   - Controls the node's own behavior (versioning, distribution formats, etc.)\n   - Can have `nodeConfigInheritanceEnabled` to determine if it inherits from parents\n\n2. **InheritableNodeConfig**: Configuration that can be passed down to child nodes\n   - Participates in inheritance chain\n   - Can be attached to Platform, Service, or Node\n   - Provides defaults for child nodes\n\n## Inheritance Hierarchy\n\nThe inheritance chain follows this precedence (most specific wins):\n\n```\n1. Node's own OperationalNodeConfig (if exists)\n2. Parent Node's InheritableNodeConfig (if exists and inheritance enabled)\n3. Grandparent Node's InheritableNodeConfig (walks up tree)\n4. Service-level InheritableNodeConfig (if exists)\n5. Platform-level InheritableNodeConfig (ultimate fallback)\n```\n\n## Resolution Algorithm\n\n### For OperationalNodeConfig\n\nWhen resolving a node's operational configuration:\n\n```typescript\nfunction resolveOperationalConfig(node: Node): OperationalNodeConfig {\n  // Step 1: Check if node has its own OperationalNodeConfig\n  if (node.hasOperationalNodeConfig) {\n    return node.operationalNodeConfig;\n  }\n  \n  // Step 2: Check if inheritance is enabled (default: true)\n  if (!node.nodeConfigInheritanceEnabled) {\n    return createDefaultOperationalConfig();\n  }\n  \n  // Step 3: Walk up the tree collecting InheritableNodeConfigs\n  const inheritanceChain = [];\n  let current = node.parent;\n  \n  while (current) {\n    if (current.hasInheritableNodeConfig) {\n      inheritanceChain.push(current.inheritableNodeConfig);\n    }\n    current = current.parent;\n  }\n  \n  // Step 4: Add service-level InheritableNodeConfig\n  if (service.hasInheritableNodeConfig) {\n    inheritanceChain.push(service.inheritableNodeConfig);\n  }\n  \n  // Step 5: Add platform-level InheritableNodeConfig\n  if (platform.hasInheritableNodeConfig) {\n    inheritanceChain.push(platform.inheritableNodeConfig);\n  }\n  \n  // Step 6: Merge configs (most specific wins)\n  return mergeConfigs(inheritanceChain.reverse());\n}\n```\n\n### For InheritableNodeConfig\n\nWhen a node needs to determine what configuration to pass to its children:\n\n```typescript\nfunction resolveInheritableConfig(node: Node): InheritableNodeConfig {\n  // Step 1: If node has its own InheritableNodeConfig, use it\n  if (node.hasInheritableNodeConfig) {\n    return node.inheritableNodeConfig;\n  }\n  \n  // Step 2: Check if inheritance propagation is enabled\n  if (!node.inheritableConfigPropagationEnabled) {\n    return null; // No config to pass down\n  }\n  \n  // Step 3: Walk up to find nearest InheritableNodeConfig\n  let current = node.parent;\n  \n  while (current) {\n    if (current.hasInheritableNodeConfig) {\n      return current.inheritableNodeConfig;\n    }\n    current = current.parent;\n  }\n  \n  // Step 4: Fall back to service-level\n  if (service.hasInheritableNodeConfig) {\n    return service.inheritableNodeConfig;\n  }\n  \n  // Step 5: Fall back to platform-level\n  return platform.inheritableNodeConfig;\n}\n```\n\n## Property-Level Inheritance\n\nConfiguration inheritance works at the property level, not all-or-nothing:\n\n```jsonld\n{\n  \"@id\": \"parent:inheritableConfig\",\n  \"@type\": \"conf:InheritableNodeConfig\",\n  \"conf:versioningEnabled\": true,\n  \"conf:distributionFormats\": [\"application/trig\", \"application/ld+json\"],\n  \"conf:generateUnifiedDataset\": true\n}\n\n{\n  \"@id\": \"child:inheritableConfig\",\n  \"@type\": \"conf:InheritableNodeConfig\",\n  \"conf:versioningEnabled\": false\n  // Inherits distributionFormats and generateUnifiedDataset from parent\n}\n```\n\n## Configuration Control Properties\n\n### nodeConfigInheritanceEnabled (Child's Perspective)\n\nControls whether a node inherits configuration from its parent hierarchy:\n- **Domain**: `conf:OperationalNodeConfig`\n- **Default**: `true`\n- **Effect**: When `false`, the node uses only its own config or system defaults\n\n### inheritableConfigPropagationEnabled (Parent's Perspective - Configuration Firewall)\n\nCreates a **configuration firewall** that blocks ALL inheritance from flowing through this node to its children:\n\n```jsonld\n{\n  \"@id\": \"conf:inheritableConfigPropagationEnabled\",\n  \"@type\": \"owl:DatatypeProperty\",\n  \"rdfs:label\": \"inheritable config propagation enabled\",\n  \"rdfs:comment\": \"Configuration firewall control. When false, blocks ALL InheritableNodeConfig from this node AND all ancestors (including Platform and Service configs) from reaching child nodes. Creates a hard configuration boundary.\",\n  \"schema:domainIncludes\": { \"@id\": \"node:Handle\" },\n  \"schema:rangeIncludes\": { \"@id\": \"xsd:boolean\" }\n}\n```\n\n**Default**: `true` - Inheritance flows normally through this node\n\n**Key Distinction**: The `inheritableConfigPropagationEnabled` property is completely independent of whether the node has its own InheritableNodeConfig:\n- A node can have `inheritableConfigPropagationEnabled: false` WITH an InheritableNodeConfig (the config exists but won't be passed down)\n- A node can have `inheritableConfigPropagationEnabled: false` WITHOUT an InheritableNodeConfig (blocks all inheritance from above)\n- When set to `false`, it creates a complete configuration barrier, blocking ALL inheritance (regardless of source) from reaching child nodes\n\n**Effect on child nodes**: They must either:\n1. Define their own complete OperationalNodeConfig\n2. Use bare platform defaults, ignoring any parent NodeConfig and any NodeConfig defaults set in the ServiceConfig\n\n## Use Cases\n\n### Platform-Wide Defaults\n\n```jsonld\n{\n  \"@id\": \"platform:config\",\n  \"@type\": \"fsvc:PlatformServiceConfig\",\n  \"conf:hasInheritableNodeConfig\": {\n    \"@type\": \"conf:InheritableNodeConfig\",\n    \"conf:versioningEnabled\": true,\n    \"conf:distributionFormats\": [\"application/trig\", \"application/ld+json\"]\n  }\n}\n```\n\n### Service-Specific Overrides\n\n```jsonld\n{\n  \"@id\": \"service:config\",\n  \"@type\": \"fsvc:ServiceConfig\",\n  \"conf:hasInheritableNodeConfig\": {\n    \"@type\": \"conf:InheritableNodeConfig\",\n    \"conf:versioningEnabled\": false  // Override platform default\n  }\n}\n```\n\n### Node with Different Operational and Inheritable Configs\n\n```jsonld\n{\n  \"@id\": \"node:handle\",\n  \"@type\": \"node:Handle\",\n  \"conf:hasOperationalNodeConfig\": {\n    \"@type\": \"conf:OperationalNodeConfig\",\n    \"conf:versioningEnabled\": false,  // This node doesn't version\n    \"conf:distributionFormats\": [\"application/trig\"]\n  },\n  \"conf:hasInheritableNodeConfig\": {\n    \"@type\": \"conf:InheritableNodeConfig\",\n    \"conf:versioningEnabled\": true,  // But children should version\n    \"conf:distributionFormats\": [\"application/trig\", \"application/ld+json\", \"text/turtle\"]\n  }\n}\n```\n\n### Configuration Firewall - Stopping ALL Inheritance\n\nWhen you need to create a hard configuration boundary that blocks ALL inheritance (not just the node's own config):\n\n```jsonld\n{\n  \"@id\": \"boundary:node\",\n  \"@type\": \"node:Handle\",\n  \"conf:inheritableConfigPropagationEnabled\": false\n  // Creates a configuration firewall - children get NO inheritance from:\n  // - This node's InheritableNodeConfig\n  // - Any parent node's InheritableNodeConfig\n  // - Service-level InheritableNodeConfig\n  // - Platform-level InheritableNodeConfig\n}\n```\n\n**Use Cases for Configuration Firewalls:**\n\n1. **Test/Development Isolation**:\n```jsonld\n{\n  \"@id\": \"test:boundary\",\n  \"@type\": \"node:Handle\",\n  \"conf:inheritableConfigPropagationEnabled\": false,\n  \"rdfs:comment\": \"Test subtree isolated from production configs\"\n}\n```\n\n2. **Multi-tenant Boundaries**:\n```jsonld\n{\n  \"@id\": \"tenant:acme:root\",\n  \"@type\": \"node:Handle\",\n  \"conf:inheritableConfigPropagationEnabled\": false,\n  \"conf:hasInheritableNodeConfig\": {\n    \"@type\": \"conf:InheritableNodeConfig\",\n    \"conf:versioningEnabled\": true,\n    \"dcterms:rightsHolder\": { \"@id\": \"https://acme.example.org\" }\n    // This InheritableNodeConfig exists but won't propagate to children\n    // because inheritableConfigPropagationEnabled is false\n  }\n}\n```\n\nNote: In this case, the node HAS an InheritableNodeConfig but blocks it from propagating. This might seem contradictory, but could be useful if the config is used for other purposes (documentation, templates, etc.) or if propagation is conditionally enabled later.\n\n3. **Legacy System Integration**:\n```jsonld\n{\n  \"@id\": \"legacy:integration:point\",\n  \"@type\": \"node:Handle\",\n  \"conf:inheritableConfigPropagationEnabled\": false,\n  \"rdfs:comment\": \"Legacy systems below this point use their own config scheme\"\n}\n```\n\n## Implementation Notes\n\n### Config Resolution Service\n\nThe config resolution service should:\n1. Cache resolved configurations for performance\n2. Invalidate cache when parent configs change\n3. Support partial config objects (only override specific properties)\n4. Validate merged configs against SHACL shapes\n\n### Default Behavior\n\n- If no configuration exists at any level, system provides sensible defaults\n- `nodeConfigInheritanceEnabled` defaults to `true`\n- `inheritableConfigPropagationEnabled` defaults to `true`\n- Empty InheritableNodeConfig means \"use all defaults\"\n\n### Migration Path\n\nFor existing systems:\n1. Convert existing NodeConfig to OperationalNodeConfig\n2. Create InheritableNodeConfig from service defaults\n3. Set `nodeConfigInheritanceEnabled` based on current behavior\n4. Gradually adopt property-level inheritance\n\n## Benefits\n\n1. **Flexibility**: Nodes can have different operational settings than what they pass to children\n2. **Granularity**: Property-level inheritance allows fine-grained control\n3. **Clarity**: Clear separation between operational and inheritable configuration\n4. **Scalability**: Platform/Service/Node hierarchy supports large deployments\n5. **Control**: Can stop inheritance at any level when needed\n\n## Complexity Management\n\nWhile the system supports sophisticated inheritance, common use cases remain simple:\n\n### Simple Case 1: Use All Defaults\n```jsonld\n{\n  \"@id\": \"simple:node\",\n  \"@type\": \"node:Handle\"\n  // Gets all config from inheritance chain\n}\n```\n\n### Simple Case 2: Override One Setting\n```jsonld\n{\n  \"@id\": \"simple:node\",\n  \"@type\": \"node:Handle\",\n  \"conf:hasOperationalNodeConfig\": {\n    \"@type\": \"conf:OperationalNodeConfig\",\n    \"conf:versioningEnabled\": false\n    // Everything else inherited\n  }\n}\n```\n\n### Simple Case 3: Service-Wide Settings\n```jsonld\n{\n  \"@id\": \"service:config\",\n  \"@type\": \"fsvc:ServiceConfig\",\n  \"conf:hasInheritableNodeConfig\": {\n    \"@type\": \"conf:InheritableNodeConfig\",\n    \"conf:versioningEnabled\": true,\n    \"conf:distributionFormats\": [\"application/trig\"]\n    // All nodes in service get these defaults\n  }\n}\n```\n\n## See Also\n\n- [[concept.mesh.resource.element.flow.config]]\n- [[concept.node-config]]\n- [[concept.mesh.resource.element.node-config-defaults]]\n","n":0.031}}},{"i":97,"$":{"0":{"v":"Documentation Resource","n":0.707}}},{"i":98,"$":{"0":{"v":"mesh resource page","n":0.577},"1":{"v":"\nTo make every folder-based resource more discoverable, they each have an index.html page that gets generate \"on [[concept.weave-process]]\"\n\n\n- primarily for humans\n\n## References\n\n- https://www.w3.org/wiki/DereferenceURI\n","n":0.209}}},{"i":99,"$":{"0":{"v":"Resource Fragment","n":0.707},"1":{"v":"\nResource fragments are [[sflo.product.service.design.htmx]] fragments, support dynamic behaviour in [[concept.mesh.resource.element.documentation-resource.resource-page]] or external web apps without a \"live\" backend.\n\nFor resource pages, they're most useful for \"saving bandwidth\": data that might not be needed can be loaded later.\n\nFor external apps, they save the overhead of parsing and discovery.\n\nFragment generation can be configured per node or inherited from config hierarchy.\n\n## **Multiple Resource Fragments in Assets**\n\nThis is a natural extension of your asset tree concept (.9):\n\n```\nmesh-node/\n├── _assets/\n│   ├── fragments/               # Generated resource pages\n│   │   ├── README.html          # generated from README.md\n│   │   ├── CHANGELOG.html       # generated from CHANGELOG.md\n│   │   └── back-references.html # list of back-references\n│   └── styles/\n│       └── common.css\n├── _meta-component/\n├── CHANGELOG.md\n└── README.md\n```\n\n","n":0.097}}},{"i":100,"$":{"0":{"v":"README","n":1},"1":{"v":"\n- Provides an unstructured introduction to the containing resource\n- preferably written in Markdown. \n","n":0.267}}},{"i":101,"$":{"0":{"v":"CHANGELOG","n":1},"1":{"v":"\n- provides an unstructure history of the containing resources\n- preferably written in Markdown. \n","n":0.267}}},{"i":102,"$":{"0":{"v":"assets tree","n":0.707},"1":{"v":"\nThis element is \"mesh-terminal\" and should contain no [[sflow-resources|concept.mesh.resource]]. \n\nIt can be contained in any [[concept.mesh.resource.folder.node]], i.e., only Nodes get assets trees.\n\nIts metadata (if any) should be stored in the closest parent node.\n\nIt can contain an arbitray set of files and folders, but two (optional) folders are special:\n- _templates can contain html files to be used when generating [[concept.mesh.resource.element.documentation-resource.resource-page]] for the containing [[concept.mesh.resource.node]] or its sub-resources.     ","n":0.123}}},{"i":103,"$":{"0":{"v":"Aggregated Distribution","n":0.707},"1":{"v":"\nA node's **aggregated distribution** is a compilation of all the data flows of all its contained nodes, situated directly under the node for easy access with an intuitive filename of \"nodename.ext\".\n\n## Purpose\n\nAggregated distributions enable **composable semantic data** by:\n- Combining component data nodes into unified resources\n- Providing complete datasets for external consumption\n- Supporting modular ontology and knowledge base construction\n- Maintaining component independence while enabling composition\n\nThis is especially useful for ontologies, when their parts are spread out\n\n## Generation Process\n\nDuring [[concept.weave-process]], aggregated distributions are created by:\n1. **Scanning contained data nodes** recursively within the mesh structure\n2. **Collecting `_data/_current/` distributions** from each component\n3. **Merging content** with proper URI resolution and prefix handling\n4. **Excluding `_ref`, `_config` and `_meta` datasets** (data content only)\n5. **Generating multiple distributions** (.ttl, .rdf, .jsonld) as configured\n\n## Examples\n\n### Composable Ontology\n```\n/my-ontology/\n├── my-ontology.ttl              ← Aggregated distribution\n├── my-ontology.rdf              ← Aggregated distribution  \n├── my-ontology.jsonld           ← Aggregated distribution\n├── components/\n│   ├── Person/                  ← Data node (class definition)\n│   ├── hasName/                 ← Data node (property definition)\n│   └── Organization/            ← Data node (class definition)\n```\n\n### Knowledge Base\n```\n/biotech-kb/\n├── biotech-kb.ttl               ← Aggregated distribution\n├── biotech-kb.jsonld            ← Aggregated distribution\n├── companies/\n│   ├── genentech/               ← Company data node\n│   └── moderna/                 ← Company data node\n└── products/\n    ├── drug-x/                  ← Product data node\n    └── vaccine-y/               ← Product data node\n```\n\n## Technical Considerations\n\n**Merging logic handles:**\n- **Relative path resolution** - Converting component-relative URIs to absolute\n- **Prefix consolidation** - Deduplicating namespace declarations\n- **Graph merging** - Combining RDF graphs from multiple sources; de-dupingz\n- **Base URI handling** - Ensuring consistent URI resolution\n\n## Use Cases\n\n- **Ontologies** - Classes and properties from component nodes\n- **Vocabularies** - Terms and definitions from specialized nodes  \n- **Catalogs** - Dataset metadata from multiple sources\n- **Knowledge bases** - Facts distributed across domain-specific nodes\n- **Configuration data** - Settings aggregated from component services\n\n## Related Concepts\n\n- **[[concept.mesh.resource.element.flow.data]]** - Source datasets for aggregation\n- **[[concept.weave-process]]** - Process that generates aggregated distributions\n- **[[concept.mesh.resource.element.flow.snapshot]]** - Contains the actual distributions being aggregated\n","n":0.058}}},{"i":104,"$":{"0":{"v":"mesh resource type","n":0.577},"1":{"v":"\nThere are three kinds of [[concept.mesh.resource]]:\n\n- [[concept.mesh.resource.node]]\n- [[concept.mesh.resource.element]]\n- [[concept.mesh.resource]]","n":0.333}}},{"i":105,"$":{"0":{"v":"user resource facet","n":0.577},"1":{"v":"\nUser resources, i.e., those that might be usually created or altered \"outside the system\" are:\n\n- [[concept.mesh.resource.element.flow.reference]]\n- [[concept.mesh.resource.element.flow.data]]\n- [[concept.mesh.resource.element.flow.config]]\n- [[concept.mesh.resource.element.asset-tree]]\n- [[concept.mesh.resource.element.documentation-resource.readme]]\n- [[concept.mesh.resource.element.documentation-resource.changelog]]\n\n## Restrictions\n\n","n":0.213}}},{"i":106,"$":{"0":{"v":"System","n":1}}},{"i":107,"$":{"0":{"v":"folder resource facet","n":0.577},"1":{"v":"\nA mesh is structured with mesh folders, which correspond to RDF resources and their [[concept.relative-identifier]]\n  \nWhen a mesh gets published, the folders also correspond to [[concept.url]]. \n\nAll folder-based resources should contain a [[concept.mesh.resource.element.documentation-resource.resource-page]]\n\n\n## Types\n\n### System Folders\n\n#### Handle Folders\n\n- [[concept.mesh.resource.folder._handle]] correspond to the [[concept.mesh.resource.element.handle]]\n\n#### Abstract Dataset Folders\n\n- **`_meta-component/`**\n  - correspond to [[concept.mesh.resource.element.flow.metadata]]\n  - present in mesh nodes and [[concept.mesh.resource.element.asset-tree]]\n\n- **`_ref-component/`**\n\n  - correspond to the [[concept.mesh.resource.node.reference]]\n  - Contains the **referent data** for [[reference-node|concept.mesh.resource.node.reference]] and optionally [[concept.mesh.resource.node.data]] (i.e., triples that say things about the thing the node represents).\n\n- **`_data-component/`**\n\n  - correspond to the [[concept.mesh.resource.element.flow.data]]\n  - contain the dataset associated with the [[concept.mesh.resource.node.data]]\n\n#### Concrete Dataset Folders\n\n- **`current/`**\n\n- **`_v1/`, `_v2/`, …**\n\n  - Version snapshot folders that represent [[concept.mesh.resource.element.flow.snapshot]]\n  - each holds one or more distribution file (named `<node_ref_vN.ext`).\n  - **Fully terminal**—neither user-nodes nor system-folders may live inside.\n\n### User Mesh Folders\n\n- **`_next`**\n  - Where edits get made to [[concept.mesh.flow-facet.versioned]]\n\n\n- **`_assets/`**\n  - Holds static user assets (images, CSS, binaries).\n  - **Always terminal** - never contains nodes\n  - Except for its `_meta` folder, is ignored by the mesh scanner.\n\n## Rejected options\n\n- directories: longer to type and most people just say folders\n- URLs/IRIs: a mesh is local-first, and we don't use the \"file:// schema\" so it\n  doesn't make sense to call these things URLs\n- folder names are used for identifiers, but identifiers are contextualized with\n  their containing path. if you're not talking about the whole path, it's really\n  just a folder.\n","n":0.066}}},{"i":108,"$":{"0":{"v":"file resource facet","n":0.577},"1":{"v":"\nResource files are returned directly when accessed by their [[concept.url]].\n\n## Types\n\n- [[concept.mesh.resource.element.documentation-resource]]\n  - [[concept.mesh.resource.element.documentation-resource.resource-page]] (system-generated)\n  - [[concept.mesh.resource.element.documentation-resource.changelog]]\n  - [[concept.mesh.resource.element.documentation-resource.readme]]\n- [[concept.mesh.resource.element.flow.snapshot.distribution]]\n- [[concept.mesh.resource.element.aggregated-distribution]]\n- ","n":0.218}}},{"i":109,"$":{"0":{"v":"dataset","n":1},"1":{"v":"\nIn the RDF universe, a dataset is a collection of one or more RDF graphs.\n\nIn a [[concept.mesh]], there are two kinds of datasets:\n  - [[concept.mesh.resource.element.flow]] are dcat:DatasetSeries (which are also dcat:Dataset) and represent an \"abstract dataset\": they don't have distributions of their own, and their data is stored in their parent node's [[concept.mesh.resource.element.flow.metadata]]'s [[concept.mesh.resource.element.flow.snapshot.distribution]]\n    - in the case of [[concept.mesh.resource.element.flow.data]], they store their own DatasetSeries metadata\n  - [[concept.mesh.resource.element.flow.snapshot]] are dcat:Dataset and represent a \"concrete dataset\": they have one or more [[related-topics.dataset.distribution]]. All of a layer's distribution files should contain the same data (they just vary in syntax)\n\n\n","n":0.102}}},{"i":110,"$":{"0":{"v":"Assets","n":1},"1":{"v":"\nEverything file in an [[concept.mesh.resource.folder._assets]] (or its subfolders) is considered an asset.\n\nEven though they will have a URL in the [[concept.namespace.base]], they are not considered \"mesh resources\".\n\n## Special Assets\n\nPrefixed with an underscore, these assets have a special role to play in the \"weave process\"\n\n\n### _weave-config.jsonld\n\n","n":0.149}}},{"i":111,"$":{"0":{"v":"mesh repo","n":0.707},"1":{"v":"\nA Semantic Flow mesh repository (or mesh repo for short) is a git repository that contains a [[concept.root-node]], and any number of additional, contained [[concept.mesh.resource.node]]\n\n\n## Github Repos\n\n- can either be \"username/org pages repository\"\" (which automatically hosts content at the namesake url, so maybe call it a namesake repository, e.g. djradon.github.io) or 2nd-level (corresponding to an owned repo)\n- a 'docs' folder that contains the generated sf site\n    - within 'docs' there's a folder for each namespace\n  \n## Questions\n\n- can you include a mesh in an existing repo?\n  - Sure!\n  - but for composability (i.e., linking a repo into an existing mesh) you need an unbroken chain, so embedding a non-root mesh has to use: \n    - maybe with symbolic links\n    - git subtree\n\n\n","n":0.091}}},{"i":112,"$":{"0":{"v":"IRI","n":1},"1":{"v":"\nIn RDF-land, resources are identified with Internationalized Resource\nIndicators. IRIs don't necessarily LOCATE a resource, i.e., if you put them in a\nweb browser, they don't necessarily return content.\n\nIn the Semantic Flow, all IRIs return a web page, so we just call them URLs.\n\nNot to mention everybody knows what a URL is, but very few know what an IRI is.\n","n":0.131}}},{"i":113,"$":{"0":{"v":"Immutability","n":1},"1":{"v":"\nImmutable data provides fundamental guarantees that enable reliable, distributed, and concurrent systems. But immutability clashes with document-oriented data the updates slowly and in chunks.\n\n- [[concept.mesh.resource.element.flow.snapshot.version]] (e.g. in [[concept.mesh.resource.folder._vN]]) should be treated as immutable. If you need to refer to the current dataset \"as is\", you should refer to its corresponding dataset version.\n- sometimes, e.g., for compliance reasons, you have to hard delete a resource (as opposed to just tombstoning it, a soft delete), or even modifying it. \n  - [[hashes|sflo.feature.changing-historical-datasets]] can be used to detect mutations\n\n## References\n\nhttps://s11.no/2013/prov/resources-that-change-state/","n":0.107}}},{"i":114,"$":{"0":{"v":"Mesh CRUD","n":0.707},"1":{"v":"\n## Operational Modalities\n\n**A. Manual Manipulation**\n- Pre-built node folder structures with user-editable layers\n- Manual mesh resource creation (nodes; flows, snapshots, distributions and other elements)\n- File-system based editing workflows\n- Validation of hand-crafted mesh structures\n\n**B. API-Driven Node Manipulation**\n- Flow-service API endpoints for programmatic node creation\n- Support for root node initialization\n- Component and element management via API\n- RESTful mesh resource manipulation\n\n**C. Dataset Distribution Upload + Extraction**\n- Upload mechanisms for RDF dataset distributions (.trig, .jsonld, etc.)\n- Automatic named entity extraction from semantic data\n- System-generated reference and data nodes\n- Batch processing of semantic data\n- **Limitation**: Cannot handle binary file resources (audio, images, etc.) - only RDF data\n- File resources must be handled via Direct Manual Construction or API-Driven modalities","n":0.094}}},{"i":115,"$":{"0":{"v":"Composability","n":1},"1":{"v":"\n//TODO: re-verify this ai-generated content\n\n## Overview\n\nComposability is the ability to combine multiple meshes or extract submeshes to create new, functional semantic structures. Semantic Flow enables flexible mesh composition through git-native operations and intelligent reference resolution.\n\n## Key Concepts\n\n### Mesh Boundaries\n\nEach git repository represents a complete mesh with its own root namespace. Cross-mesh references use absolute URIs, while intra-mesh references use relative URIs.\n\n### Upward Reference Problem\n\nWhen extracting submeshes, upward references can break. For example, if something within `ns/djradon/bio/` references `../../` (pointing to `ns/djradon/`), that reference will break if only the `bio/` subtree is copied elsewhere.\n\n### Weaving Process Solution\n\nDuring weaving, tools:\n1. **Scan for broken relatives**: Check all relative URLs in the mesh\n2. **Convert broken ones**: Replace with absolute URLs using canonical publication data\n3. **Leave working relatives alone**: Preserve transposability where possible\n\nAfter weaving, submeshes are semantically complete and can be composed using standard file operations.\n\n## Incorporating External Meshes\n\n### Importing (No External Connection)\n\nImport meshes or submeshes as permanent copies with no ongoing connection to the source:\n\n```bash\n# Method 1: Git archive (clean, can target specific paths)\ngit archive --remote=https://github.com/djradon/mesh.git main ns/djradon/ | tar -x -C collaborators/\ngit add collaborators/djradon/\ngit commit -m \"Import djradon's mesh\"\n\n# Method 2: Download and copy\ncurl -L https://github.com/djradon/mesh/archive/main.zip -o mesh.zip\nunzip mesh.zip\ncp -r mesh-main/ns/djradon/ collaborators/djradon/\ngit add collaborators/djradon/\ngit commit -m \"Import djradon's mesh\"\n```\n\nThe imported content becomes permanently part of your repository with no external dependencies.\n\n### Embedding (Maintains External Connection)\n\nEmbed external meshes while maintaining a connection for updates:\n\n```bash\n# Import with ongoing connection to source repo\ngit subtree add --prefix=collaborators/djradon/ https://github.com/djradon/mesh.git main --squash\n\n# Update embedded mesh later\ngit subtree pull --prefix=collaborators/djradon/ https://github.com/djradon/mesh.git main --squash\n```\n\nThe embedded content becomes part of your repository and site, but you can pull updates from the source repository.\n\n### Directory Structure After Incorporation\n\n```\nyour-mesh/\n├── _flow/                           # Your mesh metadata\n├── _handle/\n├── ns/\n│   └── yourdata/\n└── collaborators/\n    └── djradon/                     # Imported/embedded mesh - served as static files\n        ├── _flow/                   # Their mesh metadata\n        ├── _handle/\n        └── ns/\n            └── djradon/\n```\n\nAll files are served directly as static content when the repository is published (e.g., via GitHub Pages).\n\n## Extracting Submeshes\n\n### Post-Weave Extraction\n\nAfter weaving resolves broken references, any subtree becomes a semantically complete mesh that can be copied using standard file operations:\n\n```bash\n# Copy submesh to create standalone mesh\ncp -r ns/djradon/ ../standalone-mesh/\n\n# Copy submesh to another location (e.g., for backup)\nrsync -av collaborators/alice/ backup/alice/\n```\n\n### Pre-Weave Considerations\n\nBefore weaving, analyze upward dependencies:\n- Identify references that point outside the intended extraction boundary\n- Determine if the extracted submesh will be semantically complete\n- Consider whether broken references should become absolute URLs\n\n## Cross-Mesh References\n\n### Between Independent Meshes\n\nReferences between separate mesh repositories use absolute URIs:\n\n```turtle\n# Reference to external mesh\n<> foaf:knows <https://alice.github.io/mesh/ns/alice/> .\n```\n\n### Discovery Patterns\n\n**TBD**: Standardized mechanisms for:\n- Mesh discovery and registration\n- Stable cross-mesh URI patterns\n- Handling moved or unavailable external meshes\n\n## Composition Patterns\n\n### Collaborative Collection\n\nMultiple researchers contributing to a shared mesh:\n\n```bash\n# Add each contributor's mesh\ngit subtree add --prefix=contributors/alice/ https://alice.example/mesh.git main\ngit subtree add --prefix=contributors/bob/ https://bob.example/mesh.git main\n```\n\n### Organizational Hierarchy\n\nDepartment-level meshes within institutional mesh:\n\n```bash\n# Add department submeshes\ngit subtree add --prefix=departments/cs/ https://github.com/cs-dept/mesh.git main\ngit subtree add --prefix=departments/bio/ https://github.com/bio-dept/mesh.git main\n```\n\n### Temporal Snapshots\n\nPreserving historical versions of external meshes:\n\n```bash\n# Import specific version\ngit subtree add --prefix=snapshots/2024/djradon/ https://github.com/djradon/mesh.git v2024.1\n```\n\n## Best Practices\n\n### For Mesh Designers\n\n1. **Minimize upward references** in submesh boundaries to reduce weaving complexity\n2. **Design clear extraction points** - consider which subtrees should be independently viable\n3. **Document dependencies** - note which parts of the mesh reference external components\n4. **Use semantic boundaries** - align mesh structure with logical domain boundaries\n\n### For Mesh Composers\n\n1. **Choose import vs embed** based on maintenance needs - import for permanent copies, embed for ongoing updates\n2. **Import entire meshes** rather than attempting partial extraction from external repos\n3. **Weave before extraction** to ensure semantic completeness\n4. **Maintain incorporation metadata** - track source repositories and versions\n5. **Test extracted submeshes** independently before distribution\n\n### For Cross-Mesh References\n\n1. **Use absolute URIs** for references to external meshes\n2. **Prefer stable, canonical URIs** over temporary or redirect-based URLs\n3. **Document external dependencies** for mesh consumers\n4. **Consider fallback strategies** for unavailable external resources\n\n## Workflow Integration\n\n### Development Workflow\n1. Incorporate external meshes using import (permanent) or embed (updateable) as needed\n2. Work with relative references for local development\n3. Weave before sharing to resolve broken dependencies\n4. Test extracted submeshes independently\n\n### Maintenance Workflow\n1. For embedded meshes: periodically update with `git subtree pull`\n2. For imported meshes: manually re-import if updates are needed\n3. Re-weave after updates to handle any new broken references\n4. Validate that composition still functions correctly\n5. Update documentation of external dependencies\n\n## TBD Items\n\n- **Cross-mesh reference protocols**: Standardized discovery and resolution mechanisms\n- **Version compatibility**: Handling version mismatches between composed meshes\n- **Dependency management**: Tools for tracking and updating external mesh dependencies\n- **Conflict resolution**: Handling namespace or identifier conflicts between composed meshes\n- **Performance optimization**: Efficient composition strategies for large meshes\n\nComposability enables Semantic Flow meshes to be combined and extracted flexibly while maintaining semantic integrity through intelligent tooling and clear design patterns.","n":0.036}}}]}
